{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf24b6fa-ae03-4eda-90ba-c88ff7cbee2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.21.0\n",
      "  Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from tensorflow-addons==0.21.0) (23.2)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.21.0)\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.21.0\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8a73d1-a39d-4a0f-8f09-62d91d1a880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 26 05:21:18 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   35C    P0              26W /  70W |      2MiB / 15360MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c104503-2eb2-4d28-8b56-18754b3117a1",
   "metadata": {},
   "source": [
    "## New model with ROC-AUC and Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275b549e-42fb-400c-85b6-cb4ab214e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('L'))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape[1])\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 1])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "  ''' \n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))                     \n",
    "  model_architecture.add(Flatten())\n",
    "  model_architecture.add(Dense(64, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  '''\n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=4))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=3))\n",
    "  model_architecture.add(Flatten())\n",
    "  #model_architecture.add(Dense(32, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(16, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      model = keras.models.clone_model(model_architecture)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './images_inter_new/images'\n",
    "dir_name = './images_inter_new/models'\n",
    "file_name = './images_inter_new/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d704ed6-1df0-42e4-8aa6-23ab8e10ef9d",
   "metadata": {},
   "source": [
    "## Using a pretrained VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0494af48-b3b3-4751-ab58-4038a7d0e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = VGG16(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  #x = layers.Flatten()(model_architecture.output)\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.5\n",
    "  x = Dropout(0.5)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './mydex_trad/images'\n",
    "dir_name = './mydex_trad/models'\n",
    "file_name = './mydex_trad/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7e7d7-105e-4e32-b03f-699090596172",
   "metadata": {},
   "source": [
    "## Using a pretrained InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881576b-da89-4ea9-8632-4a48883d33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch 1/20\n",
      "26/26 - 70s - loss: 3.7002 - accuracy: 0.5230 - precision_14: 0.5186 - recall_14: 0.6403 - f1_score: 0.5731 - val_loss: 0.6740 - val_accuracy: 0.6039 - val_precision_14: 0.5919 - val_recall_14: 0.5841 - val_f1_score: 0.5880 - 70s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 59s - loss: 0.6247 - accuracy: 0.6517 - precision_14: 0.6443 - recall_14: 0.6772 - f1_score: 0.6603 - val_loss: 0.5671 - val_accuracy: 0.6981 - val_precision_14: 0.7136 - val_recall_14: 0.6283 - val_f1_score: 0.6682 - 59s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 59s - loss: 0.5612 - accuracy: 0.7091 - precision_14: 0.7167 - recall_14: 0.6915 - f1_score: 0.7039 - val_loss: 0.5259 - val_accuracy: 0.7388 - val_precision_14: 0.7549 - val_recall_14: 0.6814 - val_f1_score: 0.7163 - 59s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.5172 - accuracy: 0.7431 - precision_14: 0.7561 - recall_14: 0.7176 - f1_score: 0.7364 - val_loss: 0.4918 - val_accuracy: 0.7580 - val_precision_14: 0.7511 - val_recall_14: 0.7478 - val_f1_score: 0.7494 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.4829 - accuracy: 0.7674 - precision_14: 0.7841 - recall_14: 0.7379 - f1_score: 0.7603 - val_loss: 0.4727 - val_accuracy: 0.7880 - val_precision_14: 0.7635 - val_recall_14: 0.8142 - val_f1_score: 0.7880 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.4508 - accuracy: 0.7876 - precision_14: 0.8026 - recall_14: 0.7628 - f1_score: 0.7822 - val_loss: 0.4590 - val_accuracy: 0.7901 - val_precision_14: 0.7689 - val_recall_14: 0.8097 - val_f1_score: 0.7888 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.4347 - accuracy: 0.7956 - precision_14: 0.8115 - recall_14: 0.7700 - f1_score: 0.7902 - val_loss: 0.4433 - val_accuracy: 0.8073 - val_precision_14: 0.7906 - val_recall_14: 0.8186 - val_f1_score: 0.8043 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 58s - loss: 0.4094 - accuracy: 0.8098 - precision_14: 0.8265 - recall_14: 0.7843 - f1_score: 0.8048 - val_loss: 0.4335 - val_accuracy: 0.8116 - val_precision_14: 0.7924 - val_recall_14: 0.8274 - val_f1_score: 0.8095 - 58s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.3839 - accuracy: 0.8276 - precision_14: 0.8398 - recall_14: 0.8095 - f1_score: 0.8244 - val_loss: 0.4532 - val_accuracy: 0.8051 - val_precision_14: 0.7647 - val_recall_14: 0.8628 - val_f1_score: 0.8108 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 57s - loss: 0.3788 - accuracy: 0.8251 - precision_14: 0.8377 - recall_14: 0.8064 - f1_score: 0.8217 - val_loss: 0.4487 - val_accuracy: 0.7987 - val_precision_14: 0.7538 - val_recall_14: 0.8673 - val_f1_score: 0.8066 - 57s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.3596 - accuracy: 0.8362 - precision_14: 0.8491 - recall_14: 0.8178 - f1_score: 0.8332 - val_loss: 0.4328 - val_accuracy: 0.8094 - val_precision_14: 0.7866 - val_recall_14: 0.8319 - val_f1_score: 0.8086 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.3442 - accuracy: 0.8475 - precision_14: 0.8616 - recall_14: 0.8280 - f1_score: 0.8445 - val_loss: 0.4412 - val_accuracy: 0.8073 - val_precision_14: 0.7656 - val_recall_14: 0.8673 - val_f1_score: 0.8133 - 58s/epoch - 2s/step\n",
      "Epoch 13/20\n",
      "26/26 - 58s - loss: 0.3345 - accuracy: 0.8479 - precision_14: 0.8596 - recall_14: 0.8316 - f1_score: 0.8454 - val_loss: 0.4340 - val_accuracy: 0.8094 - val_precision_14: 0.7708 - val_recall_14: 0.8628 - val_f1_score: 0.8142 - 58s/epoch - 2s/step\n",
      "Epoch 14/20\n",
      "26/26 - 58s - loss: 0.3240 - accuracy: 0.8544 - precision_14: 0.8654 - recall_14: 0.8394 - f1_score: 0.8522 - val_loss: 0.4430 - val_accuracy: 0.7987 - val_precision_14: 0.7481 - val_recall_14: 0.8805 - val_f1_score: 0.8089 - 58s/epoch - 2s/step\n",
      "Epoch 15/20\n",
      "26/26 - 58s - loss: 0.3117 - accuracy: 0.8603 - precision_14: 0.8688 - recall_14: 0.8487 - f1_score: 0.8586 - val_loss: 0.4505 - val_accuracy: 0.8030 - val_precision_14: 0.7577 - val_recall_14: 0.8717 - val_f1_score: 0.8107 - 58s/epoch - 2s/step\n",
      "Epoch 16/20\n",
      "26/26 - 58s - loss: 0.2981 - accuracy: 0.8648 - precision_14: 0.8723 - recall_14: 0.8547 - f1_score: 0.8634 - val_loss: 0.4284 - val_accuracy: 0.8030 - val_precision_14: 0.7638 - val_recall_14: 0.8584 - val_f1_score: 0.8083 - 58s/epoch - 2s/step\n",
      "Epoch 17/20\n",
      "26/26 - 58s - loss: 0.2944 - accuracy: 0.8661 - precision_14: 0.8774 - recall_14: 0.8511 - f1_score: 0.8640 - val_loss: 0.4379 - val_accuracy: 0.8158 - val_precision_14: 0.7756 - val_recall_14: 0.8717 - val_f1_score: 0.8208 - 58s/epoch - 2s/step\n",
      "Epoch 18/20\n",
      "26/26 - 58s - loss: 0.2900 - accuracy: 0.8720 - precision_14: 0.8794 - recall_14: 0.8623 - f1_score: 0.8708 - val_loss: 0.3970 - val_accuracy: 0.8137 - val_precision_14: 0.7704 - val_recall_14: 0.8761 - val_f1_score: 0.8199 - 58s/epoch - 2s/step\n",
      "Epoch 19/20\n",
      "26/26 - 58s - loss: 0.2881 - accuracy: 0.8701 - precision_14: 0.8703 - recall_14: 0.8699 - f1_score: 0.8701 - val_loss: 0.3943 - val_accuracy: 0.8266 - val_precision_14: 0.8222 - val_recall_14: 0.8186 - val_f1_score: 0.8204 - 58s/epoch - 2s/step\n",
      "Epoch 20/20\n",
      "26/26 - 57s - loss: 0.2899 - accuracy: 0.8691 - precision_14: 0.8752 - recall_14: 0.8608 - f1_score: 0.8680 - val_loss: 0.3793 - val_accuracy: 0.8180 - val_precision_14: 0.8161 - val_recall_14: 0.8053 - val_f1_score: 0.8107 - 57s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.3099 - accuracy: 0.8803 - precision_14: 0.8623 - recall_14: 0.9064 - f1_score: 0.8838 - 4s/epoch - 154ms/step\n",
      "Run: 2\n",
      "Epoch 1/20\n",
      "26/26 - 70s - loss: 0.3093 - accuracy: 0.8613 - precision_15: 0.8561 - recall_15: 0.8707 - f1_score: 0.8633 - val_loss: 0.2192 - val_accuracy: 0.9165 - val_precision_15: 0.9254 - val_recall_15: 0.8857 - val_f1_score: 0.9051 - 70s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 58s - loss: 0.2856 - accuracy: 0.8748 - precision_15: 0.8770 - recall_15: 0.8735 - f1_score: 0.8753 - val_loss: 0.2277 - val_accuracy: 0.9101 - val_precision_15: 0.9330 - val_recall_15: 0.8619 - val_f1_score: 0.8960 - 58s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 59s - loss: 0.2643 - accuracy: 0.8857 - precision_15: 0.8930 - recall_15: 0.8780 - f1_score: 0.8854 - val_loss: 0.2195 - val_accuracy: 0.9251 - val_precision_15: 0.9108 - val_recall_15: 0.9238 - val_f1_score: 0.9173 - 59s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.2571 - accuracy: 0.8841 - precision_15: 0.8848 - recall_15: 0.8846 - f1_score: 0.8847 - val_loss: 0.2207 - val_accuracy: 0.9122 - val_precision_15: 0.9163 - val_recall_15: 0.8857 - val_f1_score: 0.9007 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.2624 - accuracy: 0.8801 - precision_15: 0.8810 - recall_15: 0.8806 - f1_score: 0.8808 - val_loss: 0.2354 - val_accuracy: 0.8994 - val_precision_15: 0.8976 - val_recall_15: 0.8762 - val_f1_score: 0.8867 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.2477 - accuracy: 0.8844 - precision_15: 0.8820 - recall_15: 0.8891 - f1_score: 0.8855 - val_loss: 0.2278 - val_accuracy: 0.9143 - val_precision_15: 0.9337 - val_recall_15: 0.8714 - val_f1_score: 0.9015 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.2462 - accuracy: 0.8908 - precision_15: 0.8904 - recall_15: 0.8929 - f1_score: 0.8916 - val_loss: 0.2343 - val_accuracy: 0.9079 - val_precision_15: 0.8995 - val_recall_15: 0.8952 - val_f1_score: 0.8974 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 58s - loss: 0.2310 - accuracy: 0.8977 - precision_15: 0.8970 - recall_15: 0.9000 - f1_score: 0.8985 - val_loss: 0.2376 - val_accuracy: 0.9015 - val_precision_15: 0.8905 - val_recall_15: 0.8905 - val_f1_score: 0.8905 - 58s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.2236 - accuracy: 0.9009 - precision_15: 0.8986 - recall_15: 0.9052 - f1_score: 0.9019 - val_loss: 0.2345 - val_accuracy: 0.9036 - val_precision_15: 0.8873 - val_recall_15: 0.9000 - val_f1_score: 0.8936 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 58s - loss: 0.2111 - accuracy: 0.9070 - precision_15: 0.9051 - recall_15: 0.9106 - f1_score: 0.9078 - val_loss: 0.2279 - val_accuracy: 0.9079 - val_precision_15: 0.8957 - val_recall_15: 0.9000 - val_f1_score: 0.8979 - 58s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.2049 - accuracy: 0.9150 - precision_15: 0.9142 - recall_15: 0.9170 - f1_score: 0.9156 - val_loss: 0.2466 - val_accuracy: 0.9015 - val_precision_15: 0.8942 - val_recall_15: 0.8857 - val_f1_score: 0.8900 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.2039 - accuracy: 0.9077 - precision_15: 0.9020 - recall_15: 0.9161 - f1_score: 0.9090 - val_loss: 0.2494 - val_accuracy: 0.8972 - val_precision_15: 0.8785 - val_recall_15: 0.8952 - val_f1_score: 0.8868 - 58s/epoch - 2s/step\n",
      "Epoch 13/20\n",
      "26/26 - 58s - loss: 0.1965 - accuracy: 0.9089 - precision_15: 0.9077 - recall_15: 0.9116 - f1_score: 0.9096 - val_loss: 0.2380 - val_accuracy: 0.8994 - val_precision_15: 0.8863 - val_recall_15: 0.8905 - val_f1_score: 0.8884 - 58s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.2836 - accuracy: 0.9017 - precision_15: 0.8802 - recall_15: 0.9261 - f1_score: 0.9025 - 4s/epoch - 155ms/step\n",
      "Run: 3\n",
      "Epoch 1/20\n",
      "26/26 - 69s - loss: 0.2669 - accuracy: 0.8846 - precision_16: 0.8853 - recall_16: 0.8824 - f1_score: 0.8839 - val_loss: 0.2674 - val_accuracy: 0.8887 - val_precision_16: 0.9194 - val_recall_16: 0.8472 - val_f1_score: 0.8818 - 69s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 58s - loss: 0.2518 - accuracy: 0.8905 - precision_16: 0.8955 - recall_16: 0.8829 - f1_score: 0.8891 - val_loss: 0.2720 - val_accuracy: 0.8929 - val_precision_16: 0.9050 - val_recall_16: 0.8734 - val_f1_score: 0.8889 - 58s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 58s - loss: 0.2323 - accuracy: 0.8994 - precision_16: 0.9000 - recall_16: 0.8974 - f1_score: 0.8987 - val_loss: 0.2770 - val_accuracy: 0.8715 - val_precision_16: 0.9289 - val_recall_16: 0.7991 - val_f1_score: 0.8592 - 58s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.2335 - accuracy: 0.8936 - precision_16: 0.8941 - recall_16: 0.8917 - f1_score: 0.8929 - val_loss: 0.3115 - val_accuracy: 0.8758 - val_precision_16: 0.8548 - val_recall_16: 0.8996 - val_f1_score: 0.8766 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.2185 - accuracy: 0.9025 - precision_16: 0.9010 - recall_16: 0.9032 - f1_score: 0.9021 - val_loss: 0.2975 - val_accuracy: 0.8672 - val_precision_16: 0.8711 - val_recall_16: 0.8559 - val_f1_score: 0.8634 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.2124 - accuracy: 0.9044 - precision_16: 0.9008 - recall_16: 0.9077 - f1_score: 0.9043 - val_loss: 0.3066 - val_accuracy: 0.8544 - val_precision_16: 0.8546 - val_recall_16: 0.8472 - val_f1_score: 0.8509 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.2049 - accuracy: 0.9109 - precision_16: 0.9078 - recall_16: 0.9137 - f1_score: 0.9108 - val_loss: 0.3141 - val_accuracy: 0.8630 - val_precision_16: 0.8873 - val_recall_16: 0.8253 - val_f1_score: 0.8552 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 57s - loss: 0.2022 - accuracy: 0.9112 - precision_16: 0.9058 - recall_16: 0.9168 - f1_score: 0.9113 - val_loss: 0.3153 - val_accuracy: 0.8587 - val_precision_16: 0.8756 - val_recall_16: 0.8297 - val_f1_score: 0.8520 - 57s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.2045 - accuracy: 0.9062 - precision_16: 0.8967 - recall_16: 0.9170 - f1_score: 0.9067 - val_loss: 0.3688 - val_accuracy: 0.8437 - val_precision_16: 0.8645 - val_recall_16: 0.8079 - val_f1_score: 0.8352 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 58s - loss: 0.2058 - accuracy: 0.9027 - precision_16: 0.8928 - recall_16: 0.9142 - f1_score: 0.9034 - val_loss: 0.3189 - val_accuracy: 0.8694 - val_precision_16: 0.8889 - val_recall_16: 0.8384 - val_f1_score: 0.8629 - 58s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.2025 - accuracy: 0.9139 - precision_16: 0.9093 - recall_16: 0.9185 - f1_score: 0.9139 - val_loss: 0.3240 - val_accuracy: 0.8565 - val_precision_16: 0.8320 - val_recall_16: 0.8865 - val_f1_score: 0.8584 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.1913 - accuracy: 0.9134 - precision_16: 0.9045 - recall_16: 0.9235 - f1_score: 0.9139 - val_loss: 0.3293 - val_accuracy: 0.8458 - val_precision_16: 0.8520 - val_recall_16: 0.8297 - val_f1_score: 0.8407 - 58s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.2764 - accuracy: 0.8974 - precision_16: 0.8906 - recall_16: 0.9255 - f1_score: 0.9077 - 4s/epoch - 155ms/step\n",
      "Run: 4\n",
      "Epoch 1/20\n",
      "26/26 - 72s - loss: 0.2493 - accuracy: 0.8921 - precision_17: 0.8914 - recall_17: 0.8924 - f1_score: 0.8919 - val_loss: 0.2066 - val_accuracy: 0.9186 - val_precision_17: 0.9304 - val_recall_17: 0.9068 - val_f1_score: 0.9185 - 72s/epoch - 3s/step\n",
      "Epoch 2/20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "'''\n",
    "def get_shape(image):\n",
    "    return image.shape[0]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,shape, 1, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE*IMG_SIZE, 1])\n",
    "    return tf.reshape(image, [IMG_SIZE*IMG_SIZE, 1,3])\n",
    "'''\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = InceptionV3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.2\n",
    "  x = Dropout(0.2)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      '''\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      '''\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      #evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      #roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      #np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './exp1/images'\n",
    "dir_name = './exp1/models'\n",
    "file_name = './exp1/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./data_splits_obfus_aug_Exp2b\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94994a66-9ee1-427d-bb61-4b89ff0e1ef9",
   "metadata": {},
   "source": [
    "## Using a pretrained ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625a6647-1230-485f-bf42-524d58009343",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './mydex_trad/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 205\u001b[0m\n\u001b[1;32m    203\u001b[0m PATH_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./myhilbert_inter_resized/data_splits\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m CLASS_NAMES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodware\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalware\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 205\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 89\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Add a final sigmoid layer with 1 node for classification output\u001b[39;00m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 89\u001b[0m file_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m file_results\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mydex_trad/results'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = ResNet50(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.2\n",
    "  x = Dropout(0.2)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './mydex_trad/images'\n",
    "dir_name = './mydex_trad/models'\n",
    "file_name = './mydex_trad/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271d0ec-8f30-4a02-bbe7-bfbba11ce98d",
   "metadata": {},
   "source": [
    "## Using a pretrained EfficientNetB0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa88a0fb-36b0-42dc-a862-c31f6d4fa40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Obtaining dependency information for efficientnet from https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl.metadata\n",
      "  Using cached efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
      "  Obtaining dependency information for keras-applications<=1.0.8,>=1.0.7 from https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl.metadata\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting scikit-image (from efficientnet)\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/33/29/1d696450464d6e13358d3ef185a1fb14a11181c5dab1eb2837c02be86373/scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.24.4)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (10.0.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for imageio>=2.27 from https://files.pythonhosted.org/packages/02/25/66533a8390e3763cf8254dee143dbf8a830391ea60d2762512ba7f9ddfbe/imageio-2.34.0-py3-none-any.whl.metadata\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/06/a3/68d17088a4f09565bc7341fd20490da8191ec4cddde479daaabbe07bb603/tifffile-2023.7.10-py3-none-any.whl.metadata\n",
      "  Using cached tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for PyWavelets>=1.1.1 from https://files.pythonhosted.org/packages/88/4b/b2b2a6f51e47c091c221bfde976a01a7e5f20e7e5e6341b2b9c4db73d2ed/PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for lazy_loader>=0.2 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Using cached efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Using cached tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, imageio, scikit-image, keras-applications, efficientnet\n",
      "Successfully installed PyWavelets-1.4.1 efficientnet-1.1.1 imageio-2.34.0 keras-applications-1.0.8 lazy_loader-0.4 scikit-image-0.21.0 tifffile-2023.7.10\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b667417-1de7-41ce-a159-68c42e61af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:32:02.628530: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 25s - loss: 2.4214 - accuracy: 0.6827 - precision: 0.6918 - recall: 0.6606 - f1_score: 0.6758 - val_loss: 0.5888 - val_accuracy: 0.7014 - val_precision: 0.6334 - val_recall: 0.9476 - val_f1_score: 0.7593 - 25s/epoch - 950ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.4564 - accuracy: 0.7851 - precision: 0.8038 - recall: 0.7552 - f1_score: 0.7787 - val_loss: 0.4062 - val_accuracy: 0.8297 - val_precision: 0.8439 - val_recall: 0.8065 - val_f1_score: 0.8247 - 6s/epoch - 229ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 6s - loss: 0.3881 - accuracy: 0.8259 - precision: 0.8497 - recall: 0.7925 - f1_score: 0.8201 - val_loss: 0.3806 - val_accuracy: 0.8437 - val_precision: 0.8542 - val_recall: 0.8266 - val_f1_score: 0.8402 - 6s/epoch - 229ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 6s - loss: 0.3625 - accuracy: 0.8415 - precision: 0.8631 - recall: 0.8123 - f1_score: 0.8369 - val_loss: 0.3632 - val_accuracy: 0.8677 - val_precision: 0.9174 - val_recall: 0.8065 - val_f1_score: 0.8584 - 6s/epoch - 241ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.3379 - accuracy: 0.8573 - precision: 0.8772 - recall: 0.8314 - f1_score: 0.8537 - val_loss: 0.3598 - val_accuracy: 0.8657 - val_precision: 0.9171 - val_recall: 0.8024 - val_f1_score: 0.8559 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.3286 - accuracy: 0.8629 - precision: 0.8883 - recall: 0.8305 - f1_score: 0.8585 - val_loss: 0.3462 - val_accuracy: 0.8657 - val_precision: 0.9132 - val_recall: 0.8065 - val_f1_score: 0.8565 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 6s - loss: 0.3146 - accuracy: 0.8664 - precision: 0.8864 - recall: 0.8410 - f1_score: 0.8631 - val_loss: 0.3441 - val_accuracy: 0.8737 - val_precision: 0.9224 - val_recall: 0.8145 - val_f1_score: 0.8651 - 6s/epoch - 229ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 6s - loss: 0.3067 - accuracy: 0.8764 - precision: 0.8985 - recall: 0.8492 - f1_score: 0.8731 - val_loss: 0.3369 - val_accuracy: 0.8798 - val_precision: 0.9196 - val_recall: 0.8306 - val_f1_score: 0.8729 - 6s/epoch - 230ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2951 - accuracy: 0.8764 - precision: 0.8972 - recall: 0.8507 - f1_score: 0.8733 - val_loss: 0.3350 - val_accuracy: 0.8737 - val_precision: 0.9224 - val_recall: 0.8145 - val_f1_score: 0.8651 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 6s - loss: 0.2828 - accuracy: 0.8851 - precision: 0.9023 - recall: 0.8641 - f1_score: 0.8828 - val_loss: 0.3261 - val_accuracy: 0.8818 - val_precision: 0.9276 - val_recall: 0.8266 - val_f1_score: 0.8742 - 6s/epoch - 229ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 6s - loss: 0.2831 - accuracy: 0.8853 - precision: 0.9062 - recall: 0.8601 - f1_score: 0.8825 - val_loss: 0.3326 - val_accuracy: 0.8898 - val_precision: 0.9251 - val_recall: 0.8468 - val_f1_score: 0.8842 - 6s/epoch - 230ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2770 - accuracy: 0.8883 - precision: 0.9071 - recall: 0.8656 - f1_score: 0.8859 - val_loss: 0.3271 - val_accuracy: 0.8798 - val_precision: 0.9352 - val_recall: 0.8145 - val_f1_score: 0.8707 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 6s - loss: 0.2655 - accuracy: 0.8922 - precision: 0.9103 - recall: 0.8705 - f1_score: 0.8900 - val_loss: 0.3195 - val_accuracy: 0.8918 - val_precision: 0.9369 - val_recall: 0.8387 - val_f1_score: 0.8851 - 6s/epoch - 228ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.2668 - accuracy: 0.8943 - precision: 0.9132 - recall: 0.8718 - f1_score: 0.8920 - val_loss: 0.3114 - val_accuracy: 0.8898 - val_precision: 0.9327 - val_recall: 0.8387 - val_f1_score: 0.8832 - 5s/epoch - 203ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2656 - accuracy: 0.8926 - precision: 0.9141 - recall: 0.8669 - f1_score: 0.8899 - val_loss: 0.3257 - val_accuracy: 0.8858 - val_precision: 0.8963 - val_recall: 0.8710 - val_f1_score: 0.8834 - 5s/epoch - 202ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 6s - loss: 0.2583 - accuracy: 0.8949 - precision: 0.9131 - recall: 0.8732 - f1_score: 0.8927 - val_loss: 0.3170 - val_accuracy: 0.9018 - val_precision: 0.9345 - val_recall: 0.8629 - val_f1_score: 0.8973 - 6s/epoch - 230ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2514 - accuracy: 0.8987 - precision: 0.9146 - recall: 0.8798 - f1_score: 0.8969 - val_loss: 0.3016 - val_accuracy: 0.8918 - val_precision: 0.9533 - val_recall: 0.8226 - val_f1_score: 0.8831 - 5s/epoch - 202ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2538 - accuracy: 0.8982 - precision: 0.9174 - recall: 0.8756 - f1_score: 0.8960 - val_loss: 0.3096 - val_accuracy: 0.9018 - val_precision: 0.9129 - val_recall: 0.8871 - val_f1_score: 0.8998 - 5s/epoch - 202ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.2430 - accuracy: 0.9003 - precision: 0.9181 - recall: 0.8794 - f1_score: 0.8983 - val_loss: 0.3042 - val_accuracy: 0.8938 - val_precision: 0.9372 - val_recall: 0.8427 - val_f1_score: 0.8875 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.2432 - accuracy: 0.9030 - precision: 0.9209 - recall: 0.8821 - f1_score: 0.9011 - val_loss: 0.3180 - val_accuracy: 0.8918 - val_precision: 0.9491 - val_recall: 0.8266 - val_f1_score: 0.8836 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.2627 - accuracy: 0.8920 - precision: 0.9283 - recall: 0.8449 - f1_score: 0.8846 - 1s/epoch - 60ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:34:49.934957: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.3824 - accuracy: 0.8395 - precision_1: 0.8452 - recall_1: 0.8322 - f1_score: 0.8386 - val_loss: 0.2527 - val_accuracy: 0.9058 - val_precision_1: 0.8727 - val_recall_1: 0.9472 - val_f1_score: 0.9084 - 21s/epoch - 800ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.2773 - accuracy: 0.8860 - precision_1: 0.9013 - recall_1: 0.8675 - f1_score: 0.8841 - val_loss: 0.2153 - val_accuracy: 0.9078 - val_precision_1: 0.9132 - val_recall_1: 0.8984 - val_f1_score: 0.9057 - 6s/epoch - 230ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 6s - loss: 0.2587 - accuracy: 0.8923 - precision_1: 0.9145 - recall_1: 0.8662 - f1_score: 0.8897 - val_loss: 0.2125 - val_accuracy: 0.9138 - val_precision_1: 0.9212 - val_recall_1: 0.9024 - val_f1_score: 0.9117 - 6s/epoch - 227ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2530 - accuracy: 0.8975 - precision_1: 0.9166 - recall_1: 0.8751 - f1_score: 0.8953 - val_loss: 0.2036 - val_accuracy: 0.9118 - val_precision_1: 0.9280 - val_recall_1: 0.8902 - val_f1_score: 0.9087 - 5s/epoch - 203ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2457 - accuracy: 0.9036 - precision_1: 0.9230 - recall_1: 0.8810 - f1_score: 0.9016 - val_loss: 0.2089 - val_accuracy: 0.9058 - val_precision_1: 0.9234 - val_recall_1: 0.8821 - val_f1_score: 0.9023 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2411 - accuracy: 0.9008 - precision_1: 0.9208 - recall_1: 0.8775 - f1_score: 0.8986 - val_loss: 0.2000 - val_accuracy: 0.9098 - val_precision_1: 0.9313 - val_recall_1: 0.8821 - val_f1_score: 0.9061 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 6s - loss: 0.2364 - accuracy: 0.9017 - precision_1: 0.9206 - recall_1: 0.8797 - f1_score: 0.8997 - val_loss: 0.2038 - val_accuracy: 0.9158 - val_precision_1: 0.9113 - val_recall_1: 0.9187 - val_f1_score: 0.9150 - 6s/epoch - 231ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.2369 - accuracy: 0.9060 - precision_1: 0.9248 - recall_1: 0.8844 - f1_score: 0.9041 - val_loss: 0.2163 - val_accuracy: 0.9098 - val_precision_1: 0.8941 - val_recall_1: 0.9268 - val_f1_score: 0.9102 - 5s/epoch - 203ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2353 - accuracy: 0.9055 - precision_1: 0.9226 - recall_1: 0.8857 - f1_score: 0.9038 - val_loss: 0.2041 - val_accuracy: 0.9098 - val_precision_1: 0.8972 - val_recall_1: 0.9228 - val_f1_score: 0.9098 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2337 - accuracy: 0.9045 - precision_1: 0.9218 - recall_1: 0.8844 - f1_score: 0.9027 - val_loss: 0.2129 - val_accuracy: 0.9138 - val_precision_1: 0.9109 - val_recall_1: 0.9146 - val_f1_score: 0.9128 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2365 - accuracy: 0.9031 - precision_1: 0.9210 - recall_1: 0.8824 - f1_score: 0.9013 - val_loss: 0.2070 - val_accuracy: 0.9138 - val_precision_1: 0.9143 - val_recall_1: 0.9106 - val_f1_score: 0.9124 - 5s/epoch - 202ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2290 - accuracy: 0.9052 - precision_1: 0.9196 - recall_1: 0.8886 - f1_score: 0.9038 - val_loss: 0.2007 - val_accuracy: 0.9158 - val_precision_1: 0.9359 - val_recall_1: 0.8902 - val_f1_score: 0.9125 - 5s/epoch - 202ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 6s - loss: 0.2230 - accuracy: 0.9079 - precision_1: 0.9222 - recall_1: 0.8915 - f1_score: 0.9066 - val_loss: 0.2239 - val_accuracy: 0.9178 - val_precision_1: 0.8868 - val_recall_1: 0.9553 - val_f1_score: 0.9198 - 6s/epoch - 230ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 6s - loss: 0.2301 - accuracy: 0.9077 - precision_1: 0.9218 - recall_1: 0.8915 - f1_score: 0.9064 - val_loss: 0.2027 - val_accuracy: 0.9198 - val_precision_1: 0.9402 - val_recall_1: 0.8943 - val_f1_score: 0.9167 - 6s/epoch - 229ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2230 - accuracy: 0.9080 - precision_1: 0.9275 - recall_1: 0.8857 - f1_score: 0.9061 - val_loss: 0.2151 - val_accuracy: 0.9118 - val_precision_1: 0.9139 - val_recall_1: 0.9065 - val_f1_score: 0.9102 - 5s/epoch - 203ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.2243 - accuracy: 0.9072 - precision_1: 0.9266 - recall_1: 0.8850 - f1_score: 0.9053 - val_loss: 0.2267 - val_accuracy: 0.9078 - val_precision_1: 0.8876 - val_recall_1: 0.9309 - val_f1_score: 0.9087 - 5s/epoch - 203ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2251 - accuracy: 0.9088 - precision_1: 0.9250 - recall_1: 0.8901 - f1_score: 0.9073 - val_loss: 0.2123 - val_accuracy: 0.9198 - val_precision_1: 0.9256 - val_recall_1: 0.9106 - val_f1_score: 0.9180 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2297 - accuracy: 0.9072 - precision_1: 0.9199 - recall_1: 0.8926 - f1_score: 0.9061 - val_loss: 0.1938 - val_accuracy: 0.9158 - val_precision_1: 0.9359 - val_recall_1: 0.8902 - val_f1_score: 0.9125 - 5s/epoch - 203ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.2132 - accuracy: 0.9140 - precision_1: 0.9314 - recall_1: 0.8944 - f1_score: 0.9125 - val_loss: 0.2027 - val_accuracy: 0.9138 - val_precision_1: 0.9394 - val_recall_1: 0.8821 - val_f1_score: 0.9099 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.2196 - accuracy: 0.9129 - precision_1: 0.9294 - recall_1: 0.8941 - f1_score: 0.9114 - val_loss: 0.2046 - val_accuracy: 0.9078 - val_precision_1: 0.9098 - val_recall_1: 0.9024 - val_f1_score: 0.9061 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1575 - accuracy: 0.9520 - precision_1: 0.9660 - recall_1: 0.9342 - f1_score: 0.9498 - 919ms/epoch - 37ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:37:26.340784: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 23s - loss: 0.2456 - accuracy: 0.8998 - precision_2: 0.9162 - recall_2: 0.8811 - f1_score: 0.8983 - val_loss: 0.1662 - val_accuracy: 0.9459 - val_precision_2: 0.9390 - val_recall_2: 0.9506 - val_f1_score: 0.9448 - 23s/epoch - 868ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 5s - loss: 0.2124 - accuracy: 0.9137 - precision_2: 0.9273 - recall_2: 0.8986 - f1_score: 0.9127 - val_loss: 0.1689 - val_accuracy: 0.9359 - val_precision_2: 0.9607 - val_recall_2: 0.9053 - val_f1_score: 0.9322 - 5s/epoch - 203ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.2100 - accuracy: 0.9124 - precision_2: 0.9317 - recall_2: 0.8908 - f1_score: 0.9108 - val_loss: 0.1725 - val_accuracy: 0.9419 - val_precision_2: 0.9213 - val_recall_2: 0.9630 - val_f1_score: 0.9416 - 5s/epoch - 203ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2088 - accuracy: 0.9137 - precision_2: 0.9309 - recall_2: 0.8946 - f1_score: 0.9124 - val_loss: 0.1667 - val_accuracy: 0.9419 - val_precision_2: 0.9612 - val_recall_2: 0.9177 - val_f1_score: 0.9389 - 5s/epoch - 203ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2056 - accuracy: 0.9171 - precision_2: 0.9359 - recall_2: 0.8963 - f1_score: 0.9157 - val_loss: 0.1810 - val_accuracy: 0.9379 - val_precision_2: 0.9454 - val_recall_2: 0.9259 - val_f1_score: 0.9356 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2097 - accuracy: 0.9128 - precision_2: 0.9289 - recall_2: 0.8948 - f1_score: 0.9116 - val_loss: 0.1669 - val_accuracy: 0.9359 - val_precision_2: 0.9528 - val_recall_2: 0.9136 - val_f1_score: 0.9328 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.2054 - accuracy: 0.9159 - precision_2: 0.9356 - recall_2: 0.8941 - f1_score: 0.9144 - val_loss: 0.1688 - val_accuracy: 0.9419 - val_precision_2: 0.9612 - val_recall_2: 0.9177 - val_f1_score: 0.9389 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.2087 - accuracy: 0.9155 - precision_2: 0.9351 - recall_2: 0.8937 - f1_score: 0.9139 - val_loss: 0.1806 - val_accuracy: 0.9379 - val_precision_2: 0.9492 - val_recall_2: 0.9218 - val_f1_score: 0.9353 - 5s/epoch - 203ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 6s - loss: 0.2077 - accuracy: 0.9144 - precision_2: 0.9344 - recall_2: 0.8921 - f1_score: 0.9128 - val_loss: 0.1599 - val_accuracy: 0.9499 - val_precision_2: 0.9467 - val_recall_2: 0.9506 - val_f1_score: 0.9487 - 6s/epoch - 229ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2085 - accuracy: 0.9166 - precision_2: 0.9343 - recall_2: 0.8970 - f1_score: 0.9153 - val_loss: 0.1757 - val_accuracy: 0.9479 - val_precision_2: 0.9465 - val_recall_2: 0.9465 - val_f1_score: 0.9465 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2086 - accuracy: 0.9159 - precision_2: 0.9326 - recall_2: 0.8975 - f1_score: 0.9147 - val_loss: 0.1663 - val_accuracy: 0.9499 - val_precision_2: 0.9504 - val_recall_2: 0.9465 - val_f1_score: 0.9485 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2031 - accuracy: 0.9179 - precision_2: 0.9301 - recall_2: 0.9045 - f1_score: 0.9171 - val_loss: 0.1710 - val_accuracy: 0.9419 - val_precision_2: 0.9534 - val_recall_2: 0.9259 - val_f1_score: 0.9395 - 5s/epoch - 204ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.2028 - accuracy: 0.9214 - precision_2: 0.9397 - recall_2: 0.9012 - f1_score: 0.9201 - val_loss: 0.1596 - val_accuracy: 0.9459 - val_precision_2: 0.9463 - val_recall_2: 0.9424 - val_f1_score: 0.9443 - 5s/epoch - 203ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.1963 - accuracy: 0.9203 - precision_2: 0.9390 - recall_2: 0.8997 - f1_score: 0.9189 - val_loss: 0.1749 - val_accuracy: 0.9419 - val_precision_2: 0.9180 - val_recall_2: 0.9671 - val_f1_score: 0.9419 - 5s/epoch - 203ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2064 - accuracy: 0.9135 - precision_2: 0.9304 - recall_2: 0.8946 - f1_score: 0.9121 - val_loss: 0.1860 - val_accuracy: 0.9419 - val_precision_2: 0.9421 - val_recall_2: 0.9383 - val_f1_score: 0.9402 - 5s/epoch - 203ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.2071 - accuracy: 0.9146 - precision_2: 0.9322 - recall_2: 0.8950 - f1_score: 0.9132 - val_loss: 0.1685 - val_accuracy: 0.9439 - val_precision_2: 0.9461 - val_recall_2: 0.9383 - val_f1_score: 0.9421 - 5s/epoch - 204ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2054 - accuracy: 0.9174 - precision_2: 0.9372 - recall_2: 0.8955 - f1_score: 0.9158 - val_loss: 0.1920 - val_accuracy: 0.9359 - val_precision_2: 0.9137 - val_recall_2: 0.9588 - val_f1_score: 0.9357 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2140 - accuracy: 0.9104 - precision_2: 0.9336 - recall_2: 0.8844 - f1_score: 0.9083 - val_loss: 0.1913 - val_accuracy: 0.9339 - val_precision_2: 0.9200 - val_recall_2: 0.9465 - val_f1_score: 0.9331 - 5s/epoch - 204ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.1970 - accuracy: 0.9197 - precision_2: 0.9377 - recall_2: 0.8999 - f1_score: 0.9184 - val_loss: 0.1727 - val_accuracy: 0.9359 - val_precision_2: 0.9528 - val_recall_2: 0.9136 - val_f1_score: 0.9328 - 5s/epoch - 209ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1546 - accuracy: 0.9460 - precision_2: 0.9605 - recall_2: 0.9241 - f1_score: 0.9419 - 963ms/epoch - 39ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:39:55.992160: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.2199 - accuracy: 0.9111 - precision_3: 0.9260 - recall_3: 0.8941 - f1_score: 0.9097 - val_loss: 0.1653 - val_accuracy: 0.9359 - val_precision_3: 0.9364 - val_recall_3: 0.9286 - val_f1_score: 0.9325 - 21s/epoch - 823ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.2047 - accuracy: 0.9176 - precision_3: 0.9340 - recall_3: 0.8990 - f1_score: 0.9162 - val_loss: 0.1479 - val_accuracy: 0.9379 - val_precision_3: 0.9641 - val_recall_3: 0.9034 - val_f1_score: 0.9328 - 6s/epoch - 233ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.1916 - accuracy: 0.9259 - precision_3: 0.9430 - recall_3: 0.9070 - f1_score: 0.9246 - val_loss: 0.1561 - val_accuracy: 0.9279 - val_precision_3: 0.9633 - val_recall_3: 0.8824 - val_f1_score: 0.9211 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.1992 - accuracy: 0.9193 - precision_3: 0.9351 - recall_3: 0.9014 - f1_score: 0.9179 - val_loss: 0.1707 - val_accuracy: 0.9238 - val_precision_3: 0.9464 - val_recall_3: 0.8908 - val_f1_score: 0.9177 - 5s/epoch - 202ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2045 - accuracy: 0.9166 - precision_3: 0.9339 - recall_3: 0.8970 - f1_score: 0.9151 - val_loss: 0.1738 - val_accuracy: 0.9238 - val_precision_3: 0.9545 - val_recall_3: 0.8824 - val_f1_score: 0.9170 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2017 - accuracy: 0.9191 - precision_3: 0.9371 - recall_3: 0.8990 - f1_score: 0.9176 - val_loss: 0.1769 - val_accuracy: 0.9138 - val_precision_3: 0.9621 - val_recall_3: 0.8529 - val_f1_score: 0.9042 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.2025 - accuracy: 0.9139 - precision_3: 0.9401 - recall_3: 0.8845 - f1_score: 0.9115 - val_loss: 0.1683 - val_accuracy: 0.9218 - val_precision_3: 0.9462 - val_recall_3: 0.8866 - val_f1_score: 0.9154 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1944 - accuracy: 0.9219 - precision_3: 0.9403 - recall_3: 0.9014 - f1_score: 0.9204 - val_loss: 0.1762 - val_accuracy: 0.9198 - val_precision_3: 0.9806 - val_recall_3: 0.8487 - val_f1_score: 0.9099 - 5s/epoch - 202ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.1976 - accuracy: 0.9146 - precision_3: 0.9364 - recall_3: 0.8899 - f1_score: 0.9126 - val_loss: 0.1738 - val_accuracy: 0.9319 - val_precision_3: 0.9474 - val_recall_3: 0.9076 - val_f1_score: 0.9270 - 5s/epoch - 202ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2077 - accuracy: 0.9126 - precision_3: 0.9399 - recall_3: 0.8819 - f1_score: 0.9100 - val_loss: 0.1719 - val_accuracy: 0.9279 - val_precision_3: 0.9720 - val_recall_3: 0.8739 - val_f1_score: 0.9204 - 5s/epoch - 202ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2055 - accuracy: 0.9132 - precision_3: 0.9381 - recall_3: 0.8852 - f1_score: 0.9109 - val_loss: 0.1671 - val_accuracy: 0.9319 - val_precision_3: 0.9554 - val_recall_3: 0.8992 - val_f1_score: 0.9264 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1994 - accuracy: 0.9200 - precision_3: 0.9435 - recall_3: 0.8939 - f1_score: 0.9180 - val_loss: 0.1772 - val_accuracy: 0.9238 - val_precision_3: 0.9464 - val_recall_3: 0.8908 - val_f1_score: 0.9177 - 5s/epoch - 207ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1427 - accuracy: 0.9380 - precision_3: 0.9587 - recall_3: 0.9170 - f1_score: 0.9374 - 953ms/epoch - 38ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:41:48.661441: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.2011 - accuracy: 0.9207 - precision_4: 0.9365 - recall_4: 0.9025 - f1_score: 0.9192 - val_loss: 0.1522 - val_accuracy: 0.9379 - val_precision_4: 0.9422 - val_recall_4: 0.9217 - val_f1_score: 0.9319 - 21s/epoch - 820ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.1961 - accuracy: 0.9193 - precision_4: 0.9329 - recall_4: 0.9034 - f1_score: 0.9179 - val_loss: 0.1568 - val_accuracy: 0.9399 - val_precision_4: 0.9808 - val_recall_4: 0.8870 - val_f1_score: 0.9315 - 6s/epoch - 231ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.2024 - accuracy: 0.9197 - precision_4: 0.9384 - recall_4: 0.8983 - f1_score: 0.9179 - val_loss: 0.1511 - val_accuracy: 0.9359 - val_precision_4: 0.9342 - val_recall_4: 0.9261 - val_f1_score: 0.9301 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2029 - accuracy: 0.9181 - precision_4: 0.9380 - recall_4: 0.8954 - f1_score: 0.9162 - val_loss: 0.1605 - val_accuracy: 0.9319 - val_precision_4: 0.9667 - val_recall_4: 0.8826 - val_f1_score: 0.9227 - 5s/epoch - 202ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.1988 - accuracy: 0.9217 - precision_4: 0.9372 - recall_4: 0.9039 - f1_score: 0.9202 - val_loss: 0.1658 - val_accuracy: 0.9299 - val_precision_4: 0.9710 - val_recall_4: 0.8739 - val_f1_score: 0.9199 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2059 - accuracy: 0.9156 - precision_4: 0.9326 - recall_4: 0.8958 - f1_score: 0.9138 - val_loss: 0.1713 - val_accuracy: 0.9319 - val_precision_4: 0.9623 - val_recall_4: 0.8870 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.1968 - accuracy: 0.9185 - precision_4: 0.9330 - recall_4: 0.9016 - f1_score: 0.9170 - val_loss: 0.1663 - val_accuracy: 0.9259 - val_precision_4: 0.9177 - val_recall_4: 0.9217 - val_f1_score: 0.9197 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1962 - accuracy: 0.9174 - precision_4: 0.9308 - recall_4: 0.9016 - f1_score: 0.9160 - val_loss: 0.1950 - val_accuracy: 0.9238 - val_precision_4: 0.9848 - val_recall_4: 0.8478 - val_f1_score: 0.9112 - 5s/epoch - 202ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2050 - accuracy: 0.9108 - precision_4: 0.9301 - recall_4: 0.8883 - f1_score: 0.9087 - val_loss: 0.1590 - val_accuracy: 0.9399 - val_precision_4: 0.9717 - val_recall_4: 0.8957 - val_f1_score: 0.9321 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 6s - loss: 0.2023 - accuracy: 0.9176 - precision_4: 0.9351 - recall_4: 0.8974 - f1_score: 0.9158 - val_loss: 0.1557 - val_accuracy: 0.9419 - val_precision_4: 0.9467 - val_recall_4: 0.9261 - val_f1_score: 0.9363 - 6s/epoch - 231ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.1953 - accuracy: 0.9174 - precision_4: 0.9356 - recall_4: 0.8963 - f1_score: 0.9155 - val_loss: 0.1625 - val_accuracy: 0.9339 - val_precision_4: 0.9191 - val_recall_4: 0.9391 - val_f1_score: 0.9290 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1887 - accuracy: 0.9234 - precision_4: 0.9356 - recall_4: 0.9092 - f1_score: 0.9222 - val_loss: 0.1615 - val_accuracy: 0.9399 - val_precision_4: 0.9464 - val_recall_4: 0.9217 - val_f1_score: 0.9339 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.1881 - accuracy: 0.9231 - precision_4: 0.9429 - recall_4: 0.9007 - f1_score: 0.9213 - val_loss: 0.1619 - val_accuracy: 0.9299 - val_precision_4: 0.9333 - val_recall_4: 0.9130 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 6s - loss: 0.1921 - accuracy: 0.9236 - precision_4: 0.9397 - recall_4: 0.9052 - f1_score: 0.9221 - val_loss: 0.1553 - val_accuracy: 0.9439 - val_precision_4: 0.9676 - val_recall_4: 0.9087 - val_f1_score: 0.9372 - 6s/epoch - 231ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 6s - loss: 0.1982 - accuracy: 0.9196 - precision_4: 0.9380 - recall_4: 0.8985 - f1_score: 0.9178 - val_loss: 0.1489 - val_accuracy: 0.9479 - val_precision_4: 0.9679 - val_recall_4: 0.9174 - val_f1_score: 0.9420 - 6s/epoch - 230ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.1949 - accuracy: 0.9207 - precision_4: 0.9383 - recall_4: 0.9005 - f1_score: 0.9190 - val_loss: 0.1604 - val_accuracy: 0.9319 - val_precision_4: 0.9623 - val_recall_4: 0.8870 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2076 - accuracy: 0.9136 - precision_4: 0.9370 - recall_4: 0.8867 - f1_score: 0.9111 - val_loss: 0.1837 - val_accuracy: 0.9138 - val_precision_4: 0.8848 - val_recall_4: 0.9348 - val_f1_score: 0.9091 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2049 - accuracy: 0.9130 - precision_4: 0.9322 - recall_4: 0.8907 - f1_score: 0.9110 - val_loss: 0.1641 - val_accuracy: 0.9359 - val_precision_4: 0.9459 - val_recall_4: 0.9130 - val_f1_score: 0.9292 - 5s/epoch - 203ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.1966 - accuracy: 0.9175 - precision_4: 0.9359 - recall_4: 0.8963 - f1_score: 0.9156 - val_loss: 0.1581 - val_accuracy: 0.9339 - val_precision_4: 0.9539 - val_recall_4: 0.9000 - val_f1_score: 0.9262 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.1971 - accuracy: 0.9156 - precision_4: 0.9364 - recall_4: 0.8916 - f1_score: 0.9135 - val_loss: 0.1772 - val_accuracy: 0.9339 - val_precision_4: 0.9668 - val_recall_4: 0.8870 - val_f1_score: 0.9252 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1708 - accuracy: 0.9380 - precision_4: 0.9582 - recall_4: 0.9265 - f1_score: 0.9421 - 976ms/epoch - 39ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1734bbd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1734bbd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 6\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:44:25.703050: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.1961 - accuracy: 0.9183 - precision_5: 0.9297 - recall_5: 0.9047 - f1_score: 0.9170 - val_loss: 0.1335 - val_accuracy: 0.9539 - val_precision_5: 0.9646 - val_recall_5: 0.9459 - val_f1_score: 0.9552 - 21s/epoch - 796ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 5s - loss: 0.1887 - accuracy: 0.9236 - precision_5: 0.9411 - recall_5: 0.9036 - f1_score: 0.9219 - val_loss: 0.1375 - val_accuracy: 0.9539 - val_precision_5: 0.9720 - val_recall_5: 0.9382 - val_f1_score: 0.9548 - 5s/epoch - 202ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.1854 - accuracy: 0.9215 - precision_5: 0.9429 - recall_5: 0.8971 - f1_score: 0.9194 - val_loss: 0.1326 - val_accuracy: 0.9459 - val_precision_5: 0.9715 - val_recall_5: 0.9228 - val_f1_score: 0.9465 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 6s - loss: 0.1836 - accuracy: 0.9255 - precision_5: 0.9456 - recall_5: 0.9027 - f1_score: 0.9237 - val_loss: 0.1418 - val_accuracy: 0.9599 - val_precision_5: 0.9723 - val_recall_5: 0.9498 - val_f1_score: 0.9609 - 6s/epoch - 229ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.1907 - accuracy: 0.9243 - precision_5: 0.9424 - recall_5: 0.9036 - f1_score: 0.9226 - val_loss: 0.1342 - val_accuracy: 0.9579 - val_precision_5: 0.9760 - val_recall_5: 0.9421 - val_f1_score: 0.9587 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.1881 - accuracy: 0.9195 - precision_5: 0.9391 - recall_5: 0.8969 - f1_score: 0.9175 - val_loss: 0.1359 - val_accuracy: 0.9579 - val_precision_5: 0.9798 - val_recall_5: 0.9382 - val_f1_score: 0.9586 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.1805 - accuracy: 0.9260 - precision_5: 0.9465 - recall_5: 0.9029 - f1_score: 0.9242 - val_loss: 0.1498 - val_accuracy: 0.9519 - val_precision_5: 0.9572 - val_recall_5: 0.9498 - val_f1_score: 0.9535 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1718 - accuracy: 0.9305 - precision_5: 0.9454 - recall_5: 0.9136 - f1_score: 0.9292 - val_loss: 0.1336 - val_accuracy: 0.9499 - val_precision_5: 0.9643 - val_recall_5: 0.9382 - val_f1_score: 0.9511 - 5s/epoch - 204ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.1721 - accuracy: 0.9280 - precision_5: 0.9453 - recall_5: 0.9085 - f1_score: 0.9265 - val_loss: 0.1399 - val_accuracy: 0.9539 - val_precision_5: 0.9609 - val_recall_5: 0.9498 - val_f1_score: 0.9553 - 5s/epoch - 202ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.1741 - accuracy: 0.9275 - precision_5: 0.9448 - recall_5: 0.9078 - f1_score: 0.9259 - val_loss: 0.1357 - val_accuracy: 0.9559 - val_precision_5: 0.9647 - val_recall_5: 0.9498 - val_f1_score: 0.9572 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.1789 - accuracy: 0.9256 - precision_5: 0.9440 - recall_5: 0.9047 - f1_score: 0.9239 - val_loss: 0.1300 - val_accuracy: 0.9579 - val_precision_5: 0.9722 - val_recall_5: 0.9459 - val_f1_score: 0.9589 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1776 - accuracy: 0.9288 - precision_5: 0.9468 - recall_5: 0.9085 - f1_score: 0.9273 - val_loss: 0.1444 - val_accuracy: 0.9519 - val_precision_5: 0.9644 - val_recall_5: 0.9421 - val_f1_score: 0.9531 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.1798 - accuracy: 0.9253 - precision_5: 0.9469 - recall_5: 0.9009 - f1_score: 0.9233 - val_loss: 0.1462 - val_accuracy: 0.9439 - val_precision_5: 0.9529 - val_recall_5: 0.9382 - val_f1_score: 0.9455 - 5s/epoch - 202ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.1799 - accuracy: 0.9246 - precision_5: 0.9478 - recall_5: 0.8984 - f1_score: 0.9225 - val_loss: 0.1489 - val_accuracy: 0.9479 - val_precision_5: 0.9605 - val_recall_5: 0.9382 - val_f1_score: 0.9492 - 5s/epoch - 207ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1594 - accuracy: 0.9480 - precision_5: 0.9583 - recall_5: 0.9350 - f1_score: 0.9465 - 914ms/epoch - 37ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f17ff6ce670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f17ff6ce670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 7\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:46:33.559844: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-17 04:46:49.749838: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at save_restore_v2_ops.cc:138 : RESOURCE_EXHAUSTED: all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__SaveV2_dtypes_324_device_/job:localhost/replica:0/task:0/device:CPU:0}} all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 205\u001b[0m\n\u001b[1;32m    203\u001b[0m PATH_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data_splits2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m CLASS_NAMES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodware\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalware\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 205\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 159\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)\u001b[0m\n\u001b[1;32m    156\u001b[0m path_save_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m    158\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 159\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time()\u001b[38;5;241m-\u001b[39mstart\n\u001b[1;32m    161\u001b[0m training_time_list\u001b[38;5;241m.\u001b[39mappend(train_time)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__SaveV2_dtypes_324_device_/job:localhost/replica:0/task:0/device:CPU:0}} all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "import efficientnet.keras as efn\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = efn.EfficientNetB0(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.5\n",
    "  x = Dropout(0.5)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './all_ds_trad_res/images'\n",
    "dir_name = './all_ds_trad_res/models'\n",
    "file_name = './all_ds_trad_res/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./data_splits2\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446d1fc-846d-4932-a199-307de4328710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
