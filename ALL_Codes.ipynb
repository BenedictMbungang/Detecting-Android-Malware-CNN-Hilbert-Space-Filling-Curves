{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf24b6fa-ae03-4eda-90ba-c88ff7cbee2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.21.0\n",
      "  Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from tensorflow-addons==0.21.0) (23.2)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.21.0)\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.21.0\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d48b48-fab9-4105-9e04-35967926b76f",
   "metadata": {},
   "source": [
    "## Experimenting with image size 128 x 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8129e4-631b-44cb-9dd8-47e239266a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('L'))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape[1])\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 1])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list = [], [], [], []\n",
    "  ''' \n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))                     \n",
    "  model_architecture.add(Flatten())\n",
    "  model_architecture.add(Dense(64, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  '''\n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=4))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=3))\n",
    "  model_architecture.add(Flatten())\n",
    "  #model_architecture.add(Dense(32, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(16, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      model = keras.models.clone_model(model_architecture)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "                             \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "      \n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "  file_results.write(\"Average scores: %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './myhilbert_inter_resized/images'\n",
    "dir_name = './myhilbert_inter_resized/models'\n",
    "file_name = './myhilbert_inter_resized/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8788b1-1d9e-4394-80da-6c5a568d26bf",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd2226-2cf6-4fd4-bbef-07abc463e8ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 4: Running our dataset on DEXRAY model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549340cd-0c7e-4baf-aa55-404a2edd513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('L'))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape[0])\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [shape, 1, 1])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE*IMG_SIZE, 1])\n",
    "    return tf.reshape(image, [IMG_SIZE*IMG_SIZE, 1])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "  \n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv1D(filters=64, kernel_size=12, activation='relu', input_shape=(IMG_SIZE*IMG_SIZE, 1)))\n",
    "  model_architecture.add(MaxPooling1D(pool_size=12))           \n",
    "  model_architecture.add(Conv1D(filters=128, kernel_size=12, activation='relu')) \n",
    "  model_architecture.add(MaxPooling1D(pool_size=12))                     \n",
    "  model_architecture.add(Flatten())\n",
    "  model_architecture.add(Dense(64, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  \n",
    "      model = keras.models.clone_model(model_architecture)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "                             \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "      \n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "\n",
    "path_images = './DEXRAY_images_new/images'\n",
    "dir_name = './DEXRAY_images_new/models'\n",
    "file_name = './DEXRAY_images_new/results'  \n",
    "  \n",
    "CHANNELS = 1\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./DEXRAY_images_new/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895040a0-4f4b-4418-aa82-b89af6f32976",
   "metadata": {},
   "source": [
    "## My Hilbert's image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1b8af4-bf1e-4e7c-9886-b9b635c30149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cef4730-4da2-49d3-8eca-94c34a60aafc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image No.  1  generated\n",
      "image No.  2  generated\n",
      "image No.  3  generated\n",
      "image No.  4  generated\n",
      "image No.  5  generated\n",
      "image No.  6  generated\n",
      "image No.  7  generated\n",
      "image No.  8  generated\n",
      "image No.  9  generated\n",
      "image No.  10  generated\n",
      "image No.  11  generated\n",
      "image No.  12  generated\n",
      "image No.  13  generated\n",
      "image No.  14  generated\n",
      "image No.  15  generated\n",
      "image No.  16  generated\n",
      "image No.  17  generated\n",
      "image No.  18  generated\n",
      "image No.  19  generated\n",
      "image No.  20  generated\n",
      "image No.  21  generated\n",
      "image No.  22  generated\n",
      "image No.  23  generated\n",
      "image No.  24  generated\n",
      "image No.  25  generated\n",
      "image No.  26  generated\n",
      "image No.  27  generated\n",
      "image No.  28  generated\n",
      "image No.  29  generated\n",
      "image No.  30  generated\n",
      "image No.  31  generated\n",
      "image No.  32  generated\n",
      "image No.  33  generated\n",
      "image No.  34  generated\n",
      "image No.  35  generated\n",
      "image No.  36  generated\n",
      "image No.  37  generated\n",
      "image No.  38  generated\n",
      "image No.  39  generated\n",
      "image No.  40  generated\n",
      "image No.  41  generated\n",
      "image No.  42  generated\n",
      "image No.  43  generated\n",
      "image No.  44  generated\n",
      "image No.  45  generated\n",
      "image No.  46  generated\n",
      "image No.  47  generated\n",
      "image No.  48  generated\n",
      "image No.  49  generated\n",
      "image No.  50  generated\n",
      "image No.  51  generated\n",
      "image No.  52  generated\n",
      "image No.  53  generated\n",
      "image No.  54  generated\n",
      "image No.  55  generated\n",
      "image No.  56  generated\n",
      "image No.  57  generated\n",
      "image No.  58  generated\n",
      "image No.  59  generated\n",
      "image No.  60  generated\n",
      "image No.  61  generated\n",
      "image No.  62  generated\n",
      "image No.  63  generated\n",
      "image No.  64  generated\n",
      "image No.  65  generated\n",
      "image No.  66  generated\n",
      "image No.  67  generated\n",
      "image No.  68  generated\n",
      "image No.  69  generated\n",
      "image No.  70  generated\n",
      "image No.  71  generated\n",
      "image No.  72  generated\n",
      "image No.  73  generated\n",
      "image No.  74  generated\n",
      "image No.  75  generated\n",
      "image No.  76  generated\n",
      "image No.  77  generated\n",
      "image No.  78  generated\n",
      "image No.  79  generated\n",
      "image No.  80  generated\n",
      "image No.  81  generated\n",
      "image No.  82  generated\n",
      "image No.  83  generated\n",
      "image No.  84  generated\n",
      "image No.  85  generated\n",
      "image No.  86  generated\n",
      "image No.  87  generated\n",
      "image No.  88  generated\n",
      "image No.  89  generated\n",
      "image No.  90  generated\n",
      "image No.  91  generated\n",
      "image No.  92  generated\n",
      "image No.  93  generated\n",
      "image No.  94  generated\n",
      "image No.  95  generated\n",
      "image No.  96  generated\n",
      "image No.  97  generated\n",
      "image No.  98  generated\n",
      "image No.  99  generated\n",
      "image No.  100  generated\n",
      "image No.  101  generated\n",
      "image No.  102  generated\n",
      "image No.  103  generated\n",
      "image No.  104  generated\n",
      "image No.  105  generated\n",
      "image No.  106  generated\n",
      "image No.  107  generated\n",
      "image No.  108  generated\n",
      "image No.  109  generated\n",
      "image No.  110  generated\n",
      "image No.  111  generated\n",
      "image No.  112  generated\n",
      "image No.  113  generated\n",
      "image No.  114  generated\n",
      "image No.  115  generated\n",
      "image No.  116  generated\n",
      "image No.  117  generated\n",
      "image No.  118  generated\n",
      "image No.  119  generated\n",
      "image No.  120  generated\n",
      "image No.  121  generated\n",
      "image No.  122  generated\n",
      "image No.  123  generated\n",
      "image No.  124  generated\n",
      "image No.  125  generated\n",
      "image No.  126  generated\n",
      "image No.  127  generated\n",
      "image No.  128  generated\n",
      "image No.  129  generated\n",
      "image No.  130  generated\n",
      "image No.  131  generated\n",
      "image No.  132  generated\n",
      "image No.  133  generated\n",
      "image No.  134  generated\n",
      "image No.  135  generated\n",
      "image No.  136  generated\n",
      "image No.  137  generated\n",
      "image No.  138  generated\n",
      "image No.  139  generated\n",
      "image No.  140  generated\n",
      "image No.  141  generated\n",
      "image No.  142  generated\n",
      "image No.  143  generated\n",
      "image No.  144  generated\n",
      "image No.  145  generated\n",
      "image No.  146  generated\n",
      "image No.  147  generated\n",
      "image No.  148  generated\n",
      "image No.  149  generated\n",
      "image No.  150  generated\n",
      "image No.  151  generated\n",
      "image No.  152  generated\n",
      "image No.  153  generated\n",
      "image No.  154  generated\n",
      "image No.  155  generated\n",
      "image No.  156  generated\n",
      "image No.  157  generated\n",
      "image No.  158  generated\n",
      "image No.  159  generated\n",
      "image No.  160  generated\n",
      "image No.  161  generated\n",
      "image No.  162  generated\n",
      "image No.  163  generated\n",
      "image No.  164  generated\n",
      "image No.  165  generated\n",
      "image No.  166  generated\n",
      "image No.  167  generated\n",
      "image No.  168  generated\n",
      "image No.  169  generated\n",
      "image No.  170  generated\n",
      "image No.  171  generated\n",
      "image No.  172  generated\n",
      "image No.  173  generated\n",
      "image No.  174  generated\n",
      "image No.  175  generated\n",
      "image No.  176  generated\n",
      "image No.  177  generated\n",
      "image No.  178  generated\n",
      "image No.  179  generated\n",
      "image No.  180  generated\n",
      "image No.  181  generated\n",
      "image No.  182  generated\n",
      "image No.  183  generated\n",
      "image No.  184  generated\n",
      "image No.  185  generated\n",
      "image No.  186  generated\n",
      "image No.  187  generated\n",
      "image No.  188  generated\n",
      "image No.  189  generated\n",
      "image No.  190  generated\n",
      "image No.  191  generated\n",
      "image No.  192  generated\n",
      "image No.  193  generated\n",
      "image No.  194  generated\n",
      "image No.  195  generated\n",
      "image No.  196  generated\n",
      "image No.  197  generated\n",
      "image No.  198  generated\n",
      "image No.  199  generated\n",
      "image No.  200  generated\n",
      "image No.  201  generated\n",
      "image No.  202  generated\n",
      "image No.  203  generated\n",
      "image No.  204  generated\n",
      "image No.  205  generated\n",
      "image No.  206  generated\n",
      "image No.  207  generated\n",
      "image No.  208  generated\n",
      "image No.  209  generated\n",
      "image No.  210  generated\n",
      "image No.  211  generated\n",
      "image No.  212  generated\n",
      "image No.  213  generated\n",
      "image No.  214  generated\n",
      "image No.  215  generated\n",
      "image No.  216  generated\n",
      "image No.  217  generated\n",
      "image No.  218  generated\n",
      "image No.  219  generated\n",
      "image No.  220  generated\n",
      "image No.  221  generated\n",
      "image No.  222  generated\n",
      "image No.  223  generated\n",
      "image No.  224  generated\n",
      "image No.  225  generated\n",
      "image No.  226  generated\n",
      "image No.  227  generated\n",
      "image No.  228  generated\n",
      "image No.  229  generated\n",
      "image No.  230  generated\n",
      "image No.  231  generated\n",
      "image No.  232  generated\n",
      "image No.  233  generated\n",
      "image No.  234  generated\n",
      "image No.  235  generated\n",
      "image No.  236  generated\n",
      "image No.  237  generated\n",
      "image No.  238  generated\n",
      "image No.  239  generated\n",
      "image No.  240  generated\n",
      "image No.  241  generated\n",
      "image No.  242  generated\n",
      "image No.  243  generated\n",
      "image No.  244  generated\n",
      "image No.  245  generated\n",
      "image No.  246  generated\n",
      "image No.  247  generated\n",
      "image No.  248  generated\n",
      "image No.  249  generated\n",
      "image No.  250  generated\n",
      "image No.  251  generated\n",
      "image No.  252  generated\n",
      "image No.  253  generated\n",
      "image No.  254  generated\n",
      "254  images successfully generated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#from tqdm.auto import tqdm\n",
    "#import time\n",
    "\n",
    "root_dir_path = './exp1'\n",
    "output_folder = './tmp'\n",
    "\n",
    "\n",
    "def last2bits(x):\n",
    "    return x & 3\n",
    "\n",
    "# returns coords [x, y] of hindex'th point of the curve\n",
    "def hilbert_coord(hindex, order):\n",
    "    positions = [[0,0], [0,1], [1,1], [1,0]]\n",
    "    tmp = positions[last2bits(hindex)]\n",
    "    x = tmp[0]\n",
    "    y = tmp[1]\n",
    "    for j in range(1, order):\n",
    "        hindex = hindex >> 2\n",
    "        n2 = 2**j\n",
    "        idx = last2bits(hindex)\n",
    "        if idx==0: # left-bottom \n",
    "            tmp = x \n",
    "            x = y \n",
    "            y = tmp\n",
    "\n",
    "        elif idx==1: # left-upper \n",
    "            x = x\n",
    "            y = y + n2\n",
    "        elif idx==2: # right-upper\n",
    "            x = x + n2\n",
    "            y = y + n2\n",
    "        else: # right-bottom\n",
    "            tmp = y\n",
    "            y = (n2-1) - x\n",
    "            x = (n2-1) - tmp\n",
    "            x = x + n2\n",
    "    return x, y\n",
    "\n",
    "def hilbert_image(order, bytestream, file_len):\n",
    "\n",
    "  size = 2**order\n",
    "  img = np.zeros((size,size), dtype=np.uint8)\n",
    "  #file_len = len(bytestream)\n",
    "  for i in range(file_len):\n",
    "      x,y = hilbert_coord(i, order)\n",
    "      img[x][y] = bytestream[i] \n",
    "      #time.sleep(0.01)\n",
    "  #print('---------------------------------------------')\n",
    "  return img\n",
    "\n",
    "\n",
    "# Loop over all data_section/DEX files in the root directory\n",
    "count=0\n",
    "for root, dirs, files in os.walk(root_dir_path):\n",
    " for filename in files:\n",
    "  # Check if the file is a bin file\n",
    "      if filename.endswith('.bin'):\n",
    "          #input_file_path\n",
    "          input_file = os.path.join(root, filename)\n",
    "          \n",
    "          # Open binary file \n",
    "          with open(input_file, 'rb') as f:\n",
    "            binary = f.read()\n",
    "\n",
    "          # calculate width, height\n",
    "          file_length = len(binary)\n",
    "          tmp = np.ceil(math.log2(file_length)/2)\n",
    "          #tmp = np.floor(math.log2(file_length)/2)\n",
    "          order = int(tmp)\n",
    "          #required_size = (2**order)*(2**order)\n",
    "\n",
    "          \n",
    "          #add padding to ensure width*height = file_length\n",
    "          #pad_length = required_size -  file_length\n",
    "          #if pad_length > 0:\n",
    "              # 0-padding \n",
    "              #binary += bytes(pad_length)\n",
    "              \n",
    "          # Hilbert's image generator\n",
    "          image = hilbert_image(order, binary, file_length)\n",
    "          \n",
    "          \n",
    "          # Convert to PIL Image\n",
    "          img = Image.fromarray(image)\n",
    "          \n",
    "          # set output image path  \n",
    "          output_path = output_folder+os.path.sep+input_file.split(os.path.sep)[-2]\n",
    "          #drop the . bin extension\n",
    "          filename1 = os.path.splitext(filename)\n",
    "          dst_file_path = os.path.join(output_path, filename1[0])\n",
    "          \n",
    "          # Save to output folder\n",
    "          img.save(dst_file_path + \"_obfuscated.png\", format=\"png\")\n",
    "          count += 1\n",
    "          print(\"image No. \",count,\" generated\")\n",
    "print(count, ' images successfully generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758e65b1-659a-4141-bcf0-9bcb5d7885f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccf948-77f1-4c36-a05f-4f4ab44ba704",
   "metadata": {},
   "source": [
    "## Traditional image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d1e520-5fb8-45e5-8d1a-70343cb2803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images successfully generated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "root_dir_path = './all_ds'\n",
    "output_folder = './all_ds_trad_img'\n",
    "\n",
    "# Loop over all files in the root directory\n",
    "for root, dirs, files in os.walk(root_dir_path):\n",
    " for filename in files:\n",
    "  # Check if the file is a bin file\n",
    "      if filename.endswith('.bin'):\n",
    "          #input_file_path\n",
    "          input_file = os.path.join(root, filename)\n",
    "          \n",
    "          # Open binary file \n",
    "          with open(input_file, 'rb') as f:\n",
    "            binary = f.read()\n",
    "\n",
    "          # calculate width, height\n",
    "          file_length = len(binary)\n",
    "          size = int(np.ceil(np.sqrt( file_length)))\n",
    "          width = size\n",
    "          height = size \n",
    "          required_size = width * height\n",
    "          \n",
    "          #add padding to ensure width*height = file_length\n",
    "          pad_length = required_size -  file_length\n",
    "          if pad_length > 0:\n",
    "              # 0-padding \n",
    "              binary += bytes(pad_length)\n",
    "              \n",
    "          # Reshape bytes to 2D array\n",
    "          image = np.frombuffer(binary, dtype=np.uint8).reshape(width, height)\n",
    "          \n",
    "          # Convert to PIL Image\n",
    "          img = Image.fromarray(image)\n",
    "          \n",
    "          # set output image path  \n",
    "          output_path = output_folder+os.path.sep+input_file.split(os.path.sep)[-2]\n",
    "          #drop the . bin extension\n",
    "          filename1 = os.path.splitext(filename)\n",
    "          dst_file_path = os.path.join(output_path, filename1[0])\n",
    "          \n",
    "          # Save to output folder\n",
    "          img.save(dst_file_path + \".png\", format=\"png\") \n",
    "print('images successfully generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5c656-4e20-464b-a49e-a32ad4c81e81",
   "metadata": {},
   "source": [
    "## Image resizing with interpolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f820f2-a6ff-47f3-9aee-ae62d8193d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6908d03e-fd33-4fb1-a87b-009a56289454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images not resized:  0 bilinear  1801 inter linear 2 images with target dims;  14946\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os \n",
    "\n",
    "\n",
    "# Path to images folder \n",
    "root_dir_path = './exp1/images'\n",
    "# Path to output folder\n",
    "resize_img_path = './tmp/images'\n",
    "# Desired resized dimensions \n",
    "target_height = 128\n",
    "target_width = 128\n",
    "\n",
    "count = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "countr = 0\n",
    "\n",
    "# Loop over all files in the root directory\n",
    "for root, dirs, files in os.walk(root_dir_path):\n",
    " for filename in files:\n",
    "  # Check if the file is a png image\n",
    "      if filename.endswith('.png'):\n",
    "        img_path = os.path.join(root, filename)\n",
    "          \n",
    "        # Read image \n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Get image shape  \n",
    "        h, w = img.shape[:2]\n",
    "        #print(\"height = \", h, \"width = \", w)\n",
    "        if h > target_height or w > target_width:\n",
    "            # Perform bilinear interpolation\n",
    "            img = cv2.resize(img, dsize=(target_height, target_width), interpolation=cv2.INTER_AREA)\n",
    "            count1 = count1 + 1\n",
    "        elif h == 0 or w==0:\n",
    "            # count images that have right size\n",
    "            count = count + 1\n",
    "        elif h == target_height and w==target_width:\n",
    "            # count images that have right size\n",
    "            countr = countr + 1\n",
    "        else:\n",
    "            # Perform resampling using pixel area relation technique\n",
    "            img = cv2.resize(img, dsize=(target_height, target_width), interpolation=cv2.INTER_LINEAR)\n",
    "            count2 = count2 + 1\n",
    "            \n",
    "            \n",
    "        # set output image path  \n",
    "        output_path = resize_img_path+os.path.sep+img_path.split(os.path.sep)[-2]\n",
    "        dst_file_path = os.path.join(output_path, filename)\n",
    "\n",
    "        # Save resized image to output path\n",
    "        #print(dst_file_path)\n",
    "        cv2.imwrite(dst_file_path, img)\n",
    "\n",
    "print('Images not resized: ', count,'bilinear ', count1, 'inter linear', count2, 'images with target dims; ', countr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4532e-56cc-430d-855e-2ce4bd222c0d",
   "metadata": {},
   "source": [
    "## Image Resizing without Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4071ed8-9f98-44cd-9318-50b7629e29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images not resized:  0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# Path to images folder \n",
    "root_dir_path = './all_ds_trad_img'\n",
    "# Path to output folder\n",
    "resize_img_path = './all_ds_trad_res/images'\n",
    "# Desired resized dimensions \n",
    "target_height = 128\n",
    "target_width = 128\n",
    "\n",
    "count = 0\n",
    "#print('PIL',PIL.__version__)\n",
    "\n",
    "# Loop over all files in the root directory\n",
    "for root, dirs, files in os.walk(root_dir_path):\n",
    " for filename in files:\n",
    "  # Check if the file is a png image\n",
    "      if filename.endswith('.png'):\n",
    "        img_path = os.path.join(root, filename)\n",
    "          \n",
    "        # Read image \n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Resize without interpolation \n",
    "        resized = img.resize((target_width, target_height))  \n",
    "            \n",
    "            \n",
    "        # set output image path  \n",
    "        output_path = resize_img_path+os.path.sep+img_path.split(os.path.sep)[-2]\n",
    "        dst_file_path = os.path.join(output_path, filename)\n",
    "\n",
    "        # Save resized image to output path\n",
    "        resized.save(dst_file_path)\n",
    "\n",
    "print('Images not resized: ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49814ae2-1d34-435f-9510-b5bb7c15a059",
   "metadata": {},
   "source": [
    "## Compares files in two folders and outputs files not found in second folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade4bd2e-c349-49a6-b21d-5540d4cf4c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255  files copied to new folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "folder1 = './obfuscated_ds/malware' \n",
    "folder2 = './obfuscated_img/malware'\n",
    "dest = './exp1'\n",
    "\n",
    "if not os.path.exists(folder1):\n",
    "    print('not seen folder1')\n",
    "    \n",
    "if not os.path.exists(folder2):\n",
    "    print('not seen  folder2')\n",
    "\n",
    "#files1 = set(os.path.splitext(f)[0] for f in os.listdir(folder1))  \n",
    "#files2 = set(os.path.splitext(f)[0] for f in os.listdir(folder2))\n",
    "\n",
    "files1 = set(os.path.splitext(f)[0] for f in os.listdir(folder1))  \n",
    "files2 = set(os.path.splitext(f)[0].replace(\"_obfuscated\", \"\")  for f in os.listdir(folder2))\n",
    "\n",
    "# Files not in folder1 but present in folder2\n",
    "#missing_in_folder1 = files2 - files1\n",
    "\n",
    "# Files not in folder2 but present in folder1 \n",
    "missing_in_folder2 = files1 - files2\n",
    "\n",
    "#print(f'Missing in folder1: {missing_in_folder1}')\n",
    "#print(f'Missing in folder2: {missing_in_folder2}')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "for file in missing_in_folder2:\n",
    "   #file = file+'.bin'\n",
    "   src_file = os.path.join(folder1, file+'.bin')  \n",
    "   dest_file = os.path.join(dest, file+'.bin')\n",
    "   if not file.startswith('.'):\n",
    "    shutil.copy(src_file, dest_file)\n",
    "\n",
    "print(len(missing_in_folder2),\" files copied to new folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b7a70-f377-412d-9866-a59effd52968",
   "metadata": {},
   "source": [
    "## Create data splits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1644168-baa8-4cbc-80c0-b302fe4973eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware image count =  7068\n",
      "goodware image count =  9681\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#import shutil\n",
    "import random\n",
    "\n",
    "random.seed(7818901)\n",
    "#print(os. getcwd())\n",
    "#rdir=os. getcwd()\n",
    "# Source and destination directories\n",
    "malware_source_dir = \"./exp1/images/malware\"\n",
    "#malware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/malware\"\n",
    "goodware_source_dir = \"./exp1/images/goodware\"\n",
    "#goodware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/goodware\"\n",
    "PATH_FILES = \"./data_splits_obfus_aug1/all.txt\"\n",
    "PATH_FILES1 = \"./data_splits_obfus_aug1/all_shuffle.txt\"\n",
    "\n",
    "malcount=0\n",
    "goodcount=0\n",
    "for path in os.listdir(malware_source_dir):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(malware_source_dir, path)):\n",
    "        malcount += 1\n",
    "print('malware image count = ', malcount)         \n",
    "for path in os.listdir(goodware_source_dir):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(goodware_source_dir, path)):\n",
    "        goodcount += 1\n",
    "print('goodware image count = ', goodcount) \n",
    "\n",
    "# Randomly select files from source directory  file\n",
    "files = random.sample(os.listdir(malware_source_dir), k=4672)\n",
    "files1 = random.sample(os.listdir(goodware_source_dir), k=4672)\n",
    "\n",
    "\n",
    "# Create text file with all images:\n",
    "with open(PATH_FILES, \"a\") as f:\n",
    "    for file in files:\n",
    "      #malware_full_source = os.path.join(malware_source_dir, file)\n",
    "      data = malware_source_dir.split(os.path.sep)[-1]+os.path.sep+file\n",
    "      f.write(data)\n",
    "      f.write('\\n')\n",
    "    for file in files1:\n",
    "      #malware_full_source = os.path.join(malware_source_dir, file)\n",
    "      data = goodware_source_dir.split(os.path.sep)[-1]+os.path.sep+file\n",
    "      f.write(data)\n",
    "      f.write('\\n')\n",
    "f.close() \n",
    "\n",
    "# Randomly reshuffling the created text file\n",
    "with open(PATH_FILES) as infile, open(PATH_FILES1, 'w') as outfile:\n",
    "    lines = infile.readlines()\n",
    "    indices = list(range(len(lines)))\n",
    "    random.shuffle(indices)\n",
    "    for i in indices:\n",
    "      outfile.write(lines[i])\n",
    "infile.close()\n",
    "outfile.close()\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beeed2a-a43d-4a21-9797-09cfb52e93bb",
   "metadata": {},
   "source": [
    "## 5. Use k-fold cross validation to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a533125e-73d7-413c-8d24-bec59e15ad2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Fold 2:\n",
      "Fold 3:\n",
      "Fold 4:\n",
      "Fold 5:\n",
      "Fold 6:\n",
      "Fold 7:\n",
      "Fold 8:\n",
      "Fold 9:\n",
      "Fold 10:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "PATH_FILES1 = \"./data_splits_obfus_aug1\"\n",
    "PATH_FILES = \"./data_splits_obfus_aug1/all_shuffle.txt\"\n",
    "\n",
    "#sample size+1 total size +1 is 9345\n",
    "k=9345\n",
    "\n",
    "X = np.array([i for i in range(1,k)])\n",
    "#y = np.array([1, 2, 3, 4])\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "#kf.get_n_splits(X)\n",
    "#print(kf)\n",
    "with open(PATH_FILES) as infile:\n",
    "    lines = infile.readlines()\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "         print(f\"Fold {i+1}:\")\n",
    "         train_file_path = os.path.join(PATH_FILES1, \"train\"+str(i+1)+\".txt\")\n",
    "         test_file_path = os.path.join(PATH_FILES1, \"test\"+str(i+1)+\".txt\")\n",
    "         valid_file_path = os.path.join(PATH_FILES1, \"valid\"+str(i+1)+\".txt\")\n",
    "         with open(train_file_path, 'w') as trainfile, open(test_file_path, 'w') as testfile, open(valid_file_path, 'w') as validfile:\n",
    "            for j in train_index:\n",
    "              trainfile.write(lines[j])\n",
    "            new_test_index = np.array_split(test_index,2)[0]\n",
    "            for j in new_test_index:\n",
    "              testfile.write(lines[j])\n",
    "            valid_index = np.array_split(test_index,2)[1]\n",
    "            for j in valid_index:\n",
    "              validfile.write(lines[j])\n",
    "         trainfile.close()\n",
    "         testfile.close()\n",
    "         validfile.close()\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fac8-48cc-4dd7-8e2d-2b33e1b6f083",
   "metadata": {},
   "source": [
    "## Creating obfuscated test sets from the non-obfuscated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b20ee2f-714a-423b-8d05-48cb5b3b7d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Length of testfile set   468\n",
      "Length of same is   322\n",
      "Length of obfus file set   428\n",
      "Randomly select 146 obfuscated files for test1 file\n",
      "Writing 468 lines in test1 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 2:\n",
      "Length of testfile set   468\n",
      "Length of same is   332\n",
      "Length of obfus file set   428\n",
      "Randomly select 136 obfuscated files for test2 file\n",
      "Writing 468 lines in test2 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 3:\n",
      "Length of testfile set   468\n",
      "Length of same is   293\n",
      "Length of obfus file set   428\n",
      "Randomly select 175 obfuscated files for test3 file\n",
      "Writing 468 lines in test3 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 4:\n",
      "Length of testfile set   467\n",
      "Length of same is   302\n",
      "Length of obfus file set   428\n",
      "Randomly select 165 obfuscated files for test4 file\n",
      "Writing 467 lines in test4 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 5:\n",
      "Length of testfile set   467\n",
      "Length of same is   323\n",
      "Length of obfus file set   428\n",
      "Randomly select 144 obfuscated files for test5 file\n",
      "Writing 467 lines in test5 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 6:\n",
      "Length of testfile set   467\n",
      "Length of same is   314\n",
      "Length of obfus file set   428\n",
      "Randomly select 153 obfuscated files for test6 file\n",
      "Writing 467 lines in test6 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 7:\n",
      "Length of testfile set   467\n",
      "Length of same is   331\n",
      "Length of obfus file set   428\n",
      "Randomly select 136 obfuscated files for test7 file\n",
      "Writing 467 lines in test7 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 8:\n",
      "Length of testfile set   467\n",
      "Length of same is   311\n",
      "Length of obfus file set   428\n",
      "Randomly select 156 obfuscated files for test8 file\n",
      "Writing 467 lines in test8 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 9:\n",
      "Length of testfile set   467\n",
      "Length of same is   322\n",
      "Length of obfus file set   428\n",
      "Randomly select 145 obfuscated files for test9 file\n",
      "Writing 467 lines in test9 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 10:\n",
      "Length of testfile set   467\n",
      "Length of same is   301\n",
      "Length of obfus file set   428\n",
      "Randomly select 166 obfuscated files for test10 file\n",
      "Writing 467 lines in test10 file\n",
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130/116891691.py:51: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  same = same | set(random.sample(obfus_file_set, len(testfile_set)))\n"
     ]
    }
   ],
   "source": [
    "# Input files: train, test, and valid files generated fron the non-obfuscated dataset\n",
    "# Input file: all_obfuscated.txt file containing all obfuscated samples randomly shuffled\n",
    "# Output: train, test, and valid files with test files samples replaced by their corresponding obfusated counterparts if present. \n",
    "#         If not select a file at random from all_obfuscated.txt which is not found in the train, valid or test datasets\n",
    "\n",
    "import os \n",
    "import random\n",
    "\n",
    "#setting up input/output files and/or folders \n",
    "non_obfuscated_path = \"./data_splits_hilbert\"\n",
    "all_obfuscated_files = \"./data_splits_obfuscated1/all_shuffle.txt\"\n",
    "obfus_test_path = \"./data_splits_obfuscated1\"\n",
    "\n",
    "#looping through the 10 test files\n",
    "for i in range(1,11):\n",
    "    print(f\"Fold {i}:\")\n",
    "    #setting input files paths\n",
    "    train_file_path = os.path.join(non_obfuscated_path, \"train\"+str(i)+\".txt\")\n",
    "    test_file_path = os.path.join(non_obfuscated_path, \"test\"+str(i)+\".txt\")\n",
    "    valid_file_path = os.path.join(non_obfuscated_path, \"valid\"+str(i)+\".txt\")\n",
    "    with open(all_obfuscated_files, 'r')  as obfus_file, open(test_file_path, 'r') as testfile, open(train_file_path, 'r') as trainfile, open(valid_file_path, 'r') as validfile:\n",
    "        #get equivalent obfuscated versions of test files\n",
    "        testfile_lines = testfile.readlines()\n",
    "        obfusfile_lines = obfus_file.readlines()\n",
    "        testfile_set = set(testfile_lines)\n",
    "        #obfus_file_set = set(obfusfile_lines)\n",
    "        obfus_file_set = set(f.replace(\"_obfuscated\", \"\")  for f in obfusfile_lines)\n",
    "        print(\"Length of testfile set  \", len( testfile_set))\n",
    "        same = obfus_file_set & testfile_set\n",
    "        print(\"Length of same is  \", len(same))\n",
    "        #remove files in testset that are already n the obfuscated dataset\n",
    "        testfile_set.difference_update(obfus_file_set)\n",
    "        if len(testfile_set) == 0:\n",
    "            print(f\"Great!!! All files in test{i} have obfuscated versions\")\n",
    "        else:\n",
    "            trainfile_lines = trainfile.readlines()\n",
    "            validfile_lines = validfile.readlines()\n",
    "            trainfile_set = set(trainfile_lines)\n",
    "            validfile_set = set(validfile_lines)\n",
    "            #Create universal set of files that can n longer be included in the testset\n",
    "            all_set = same | trainfile_set | validfile_set\n",
    "            obfus_file_set.difference_update(all_set)\n",
    "            print(\"Length of obfus file set  \", len( obfus_file_set ))\n",
    "            if len(obfus_file_set)==0:\n",
    "                print(f\"All obfuscated files are already in trainset, validset and test{i}\")\n",
    "            elif len(obfus_file_set)<=len(testfile_set):\n",
    "                print(f\"All obfuscated less than or equal to required obfuscated test{i}\")\n",
    "                same = same | obfus_file_set\n",
    "            else:\n",
    "                print(f\"Randomly select {len(testfile_set)} obfuscated files for test{i} file\")\n",
    "                same = same | set(random.sample(obfus_file_set, len(testfile_set)))\n",
    "        #Create new obfuscated test file\n",
    "        new_test_file_path = os.path.join(obfus_test_path, \"test\"+str(i)+\".txt\")\n",
    "        with open(new_test_file_path, 'w') as new_test_file:\n",
    "            if len(same) == 0:\n",
    "                print(f\"Fatal error:Obfuscated testset is empty for test{i} file\")\n",
    "                for line in testfile_lines:\n",
    "                     new_test_file.write(line.replace(\".png\",\"_obfuscated.png\"))\n",
    "            else:\n",
    "                print(f\"Writing {len(same)} lines in test{i} file\")\n",
    "                for line in same:\n",
    "                     new_test_file.write(line.replace(\".png\",\"_obfuscated.png\"))\n",
    "        new_test_file.close()\n",
    "    obfus_file.close()\n",
    "    trainfile.close()\n",
    "    testfile.close()\n",
    "    validfile.close()\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea944e63-aeee-46d2-a191-6b48d2e23844",
   "metadata": {},
   "source": [
    "## copy files from one directory to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12203d2e-df59-48f7-8faa-c6bb16b9924f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files move count =  2073\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "dest_dir = './exp1/images/malware'\n",
    "#malware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/malware\"\n",
    "source_dir = \"./obfuscated_img/malware\"\n",
    "#goodware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/goodware\"\n",
    "\n",
    "\n",
    "count=0\n",
    "for path in os.listdir(source_dir):\n",
    "    # check if current path is a file\n",
    "    file = os.path.join(source_dir, path)\n",
    "    file1 = os.path.join(dest_dir, path)\n",
    "    if os.path.isfile(file):\n",
    "        shutil.copy(file,file1)\n",
    "        count += 1\n",
    "print('files move count = ',count)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8a73d1-a39d-4a0f-8f09-62d91d1a880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 26 05:21:18 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   35C    P0              26W /  70W |      2MiB / 15360MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c104503-2eb2-4d28-8b56-18754b3117a1",
   "metadata": {},
   "source": [
    "## New model with ROC-AUC and Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275b549e-42fb-400c-85b6-cb4ab214e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('L'))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape[1])\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 1])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "  ''' \n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=2))                     \n",
    "  model_architecture.add(Flatten())\n",
    "  model_architecture.add(Dense(64, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  '''\n",
    "  model_architecture = Sequential()           \n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "  model_architecture.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(MaxPooling2D(pool_size=4))           \n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "  model_architecture.add(Conv2D(filters=128, kernel_size=3, activation='relu')) \n",
    "  model_architecture.add(MaxPooling2D(pool_size=3))\n",
    "  model_architecture.add(Flatten())\n",
    "  #model_architecture.add(Dense(32, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(16, activation='sigmoid'))\n",
    "  model_architecture.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      model = keras.models.clone_model(model_architecture)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './images_inter_new/images'\n",
    "dir_name = './images_inter_new/models'\n",
    "file_name = './images_inter_new/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d704ed6-1df0-42e4-8aa6-23ab8e10ef9d",
   "metadata": {},
   "source": [
    "## Using a pretrained VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0494af48-b3b3-4751-ab58-4038a7d0e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = VGG16(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  #x = layers.Flatten()(model_architecture.output)\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.5\n",
    "  x = Dropout(0.5)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './mydex_trad/images'\n",
    "dir_name = './mydex_trad/models'\n",
    "file_name = './mydex_trad/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7e7d7-105e-4e32-b03f-699090596172",
   "metadata": {},
   "source": [
    "## Using a pretrained InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881576b-da89-4ea9-8632-4a48883d33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch 1/20\n",
      "26/26 - 70s - loss: 3.7002 - accuracy: 0.5230 - precision_14: 0.5186 - recall_14: 0.6403 - f1_score: 0.5731 - val_loss: 0.6740 - val_accuracy: 0.6039 - val_precision_14: 0.5919 - val_recall_14: 0.5841 - val_f1_score: 0.5880 - 70s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 59s - loss: 0.6247 - accuracy: 0.6517 - precision_14: 0.6443 - recall_14: 0.6772 - f1_score: 0.6603 - val_loss: 0.5671 - val_accuracy: 0.6981 - val_precision_14: 0.7136 - val_recall_14: 0.6283 - val_f1_score: 0.6682 - 59s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 59s - loss: 0.5612 - accuracy: 0.7091 - precision_14: 0.7167 - recall_14: 0.6915 - f1_score: 0.7039 - val_loss: 0.5259 - val_accuracy: 0.7388 - val_precision_14: 0.7549 - val_recall_14: 0.6814 - val_f1_score: 0.7163 - 59s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.5172 - accuracy: 0.7431 - precision_14: 0.7561 - recall_14: 0.7176 - f1_score: 0.7364 - val_loss: 0.4918 - val_accuracy: 0.7580 - val_precision_14: 0.7511 - val_recall_14: 0.7478 - val_f1_score: 0.7494 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.4829 - accuracy: 0.7674 - precision_14: 0.7841 - recall_14: 0.7379 - f1_score: 0.7603 - val_loss: 0.4727 - val_accuracy: 0.7880 - val_precision_14: 0.7635 - val_recall_14: 0.8142 - val_f1_score: 0.7880 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.4508 - accuracy: 0.7876 - precision_14: 0.8026 - recall_14: 0.7628 - f1_score: 0.7822 - val_loss: 0.4590 - val_accuracy: 0.7901 - val_precision_14: 0.7689 - val_recall_14: 0.8097 - val_f1_score: 0.7888 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.4347 - accuracy: 0.7956 - precision_14: 0.8115 - recall_14: 0.7700 - f1_score: 0.7902 - val_loss: 0.4433 - val_accuracy: 0.8073 - val_precision_14: 0.7906 - val_recall_14: 0.8186 - val_f1_score: 0.8043 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 58s - loss: 0.4094 - accuracy: 0.8098 - precision_14: 0.8265 - recall_14: 0.7843 - f1_score: 0.8048 - val_loss: 0.4335 - val_accuracy: 0.8116 - val_precision_14: 0.7924 - val_recall_14: 0.8274 - val_f1_score: 0.8095 - 58s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.3839 - accuracy: 0.8276 - precision_14: 0.8398 - recall_14: 0.8095 - f1_score: 0.8244 - val_loss: 0.4532 - val_accuracy: 0.8051 - val_precision_14: 0.7647 - val_recall_14: 0.8628 - val_f1_score: 0.8108 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 57s - loss: 0.3788 - accuracy: 0.8251 - precision_14: 0.8377 - recall_14: 0.8064 - f1_score: 0.8217 - val_loss: 0.4487 - val_accuracy: 0.7987 - val_precision_14: 0.7538 - val_recall_14: 0.8673 - val_f1_score: 0.8066 - 57s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.3596 - accuracy: 0.8362 - precision_14: 0.8491 - recall_14: 0.8178 - f1_score: 0.8332 - val_loss: 0.4328 - val_accuracy: 0.8094 - val_precision_14: 0.7866 - val_recall_14: 0.8319 - val_f1_score: 0.8086 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.3442 - accuracy: 0.8475 - precision_14: 0.8616 - recall_14: 0.8280 - f1_score: 0.8445 - val_loss: 0.4412 - val_accuracy: 0.8073 - val_precision_14: 0.7656 - val_recall_14: 0.8673 - val_f1_score: 0.8133 - 58s/epoch - 2s/step\n",
      "Epoch 13/20\n",
      "26/26 - 58s - loss: 0.3345 - accuracy: 0.8479 - precision_14: 0.8596 - recall_14: 0.8316 - f1_score: 0.8454 - val_loss: 0.4340 - val_accuracy: 0.8094 - val_precision_14: 0.7708 - val_recall_14: 0.8628 - val_f1_score: 0.8142 - 58s/epoch - 2s/step\n",
      "Epoch 14/20\n",
      "26/26 - 58s - loss: 0.3240 - accuracy: 0.8544 - precision_14: 0.8654 - recall_14: 0.8394 - f1_score: 0.8522 - val_loss: 0.4430 - val_accuracy: 0.7987 - val_precision_14: 0.7481 - val_recall_14: 0.8805 - val_f1_score: 0.8089 - 58s/epoch - 2s/step\n",
      "Epoch 15/20\n",
      "26/26 - 58s - loss: 0.3117 - accuracy: 0.8603 - precision_14: 0.8688 - recall_14: 0.8487 - f1_score: 0.8586 - val_loss: 0.4505 - val_accuracy: 0.8030 - val_precision_14: 0.7577 - val_recall_14: 0.8717 - val_f1_score: 0.8107 - 58s/epoch - 2s/step\n",
      "Epoch 16/20\n",
      "26/26 - 58s - loss: 0.2981 - accuracy: 0.8648 - precision_14: 0.8723 - recall_14: 0.8547 - f1_score: 0.8634 - val_loss: 0.4284 - val_accuracy: 0.8030 - val_precision_14: 0.7638 - val_recall_14: 0.8584 - val_f1_score: 0.8083 - 58s/epoch - 2s/step\n",
      "Epoch 17/20\n",
      "26/26 - 58s - loss: 0.2944 - accuracy: 0.8661 - precision_14: 0.8774 - recall_14: 0.8511 - f1_score: 0.8640 - val_loss: 0.4379 - val_accuracy: 0.8158 - val_precision_14: 0.7756 - val_recall_14: 0.8717 - val_f1_score: 0.8208 - 58s/epoch - 2s/step\n",
      "Epoch 18/20\n",
      "26/26 - 58s - loss: 0.2900 - accuracy: 0.8720 - precision_14: 0.8794 - recall_14: 0.8623 - f1_score: 0.8708 - val_loss: 0.3970 - val_accuracy: 0.8137 - val_precision_14: 0.7704 - val_recall_14: 0.8761 - val_f1_score: 0.8199 - 58s/epoch - 2s/step\n",
      "Epoch 19/20\n",
      "26/26 - 58s - loss: 0.2881 - accuracy: 0.8701 - precision_14: 0.8703 - recall_14: 0.8699 - f1_score: 0.8701 - val_loss: 0.3943 - val_accuracy: 0.8266 - val_precision_14: 0.8222 - val_recall_14: 0.8186 - val_f1_score: 0.8204 - 58s/epoch - 2s/step\n",
      "Epoch 20/20\n",
      "26/26 - 57s - loss: 0.2899 - accuracy: 0.8691 - precision_14: 0.8752 - recall_14: 0.8608 - f1_score: 0.8680 - val_loss: 0.3793 - val_accuracy: 0.8180 - val_precision_14: 0.8161 - val_recall_14: 0.8053 - val_f1_score: 0.8107 - 57s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.3099 - accuracy: 0.8803 - precision_14: 0.8623 - recall_14: 0.9064 - f1_score: 0.8838 - 4s/epoch - 154ms/step\n",
      "Run: 2\n",
      "Epoch 1/20\n",
      "26/26 - 70s - loss: 0.3093 - accuracy: 0.8613 - precision_15: 0.8561 - recall_15: 0.8707 - f1_score: 0.8633 - val_loss: 0.2192 - val_accuracy: 0.9165 - val_precision_15: 0.9254 - val_recall_15: 0.8857 - val_f1_score: 0.9051 - 70s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 58s - loss: 0.2856 - accuracy: 0.8748 - precision_15: 0.8770 - recall_15: 0.8735 - f1_score: 0.8753 - val_loss: 0.2277 - val_accuracy: 0.9101 - val_precision_15: 0.9330 - val_recall_15: 0.8619 - val_f1_score: 0.8960 - 58s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 59s - loss: 0.2643 - accuracy: 0.8857 - precision_15: 0.8930 - recall_15: 0.8780 - f1_score: 0.8854 - val_loss: 0.2195 - val_accuracy: 0.9251 - val_precision_15: 0.9108 - val_recall_15: 0.9238 - val_f1_score: 0.9173 - 59s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.2571 - accuracy: 0.8841 - precision_15: 0.8848 - recall_15: 0.8846 - f1_score: 0.8847 - val_loss: 0.2207 - val_accuracy: 0.9122 - val_precision_15: 0.9163 - val_recall_15: 0.8857 - val_f1_score: 0.9007 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.2624 - accuracy: 0.8801 - precision_15: 0.8810 - recall_15: 0.8806 - f1_score: 0.8808 - val_loss: 0.2354 - val_accuracy: 0.8994 - val_precision_15: 0.8976 - val_recall_15: 0.8762 - val_f1_score: 0.8867 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.2477 - accuracy: 0.8844 - precision_15: 0.8820 - recall_15: 0.8891 - f1_score: 0.8855 - val_loss: 0.2278 - val_accuracy: 0.9143 - val_precision_15: 0.9337 - val_recall_15: 0.8714 - val_f1_score: 0.9015 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.2462 - accuracy: 0.8908 - precision_15: 0.8904 - recall_15: 0.8929 - f1_score: 0.8916 - val_loss: 0.2343 - val_accuracy: 0.9079 - val_precision_15: 0.8995 - val_recall_15: 0.8952 - val_f1_score: 0.8974 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 58s - loss: 0.2310 - accuracy: 0.8977 - precision_15: 0.8970 - recall_15: 0.9000 - f1_score: 0.8985 - val_loss: 0.2376 - val_accuracy: 0.9015 - val_precision_15: 0.8905 - val_recall_15: 0.8905 - val_f1_score: 0.8905 - 58s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.2236 - accuracy: 0.9009 - precision_15: 0.8986 - recall_15: 0.9052 - f1_score: 0.9019 - val_loss: 0.2345 - val_accuracy: 0.9036 - val_precision_15: 0.8873 - val_recall_15: 0.9000 - val_f1_score: 0.8936 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 58s - loss: 0.2111 - accuracy: 0.9070 - precision_15: 0.9051 - recall_15: 0.9106 - f1_score: 0.9078 - val_loss: 0.2279 - val_accuracy: 0.9079 - val_precision_15: 0.8957 - val_recall_15: 0.9000 - val_f1_score: 0.8979 - 58s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.2049 - accuracy: 0.9150 - precision_15: 0.9142 - recall_15: 0.9170 - f1_score: 0.9156 - val_loss: 0.2466 - val_accuracy: 0.9015 - val_precision_15: 0.8942 - val_recall_15: 0.8857 - val_f1_score: 0.8900 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.2039 - accuracy: 0.9077 - precision_15: 0.9020 - recall_15: 0.9161 - f1_score: 0.9090 - val_loss: 0.2494 - val_accuracy: 0.8972 - val_precision_15: 0.8785 - val_recall_15: 0.8952 - val_f1_score: 0.8868 - 58s/epoch - 2s/step\n",
      "Epoch 13/20\n",
      "26/26 - 58s - loss: 0.1965 - accuracy: 0.9089 - precision_15: 0.9077 - recall_15: 0.9116 - f1_score: 0.9096 - val_loss: 0.2380 - val_accuracy: 0.8994 - val_precision_15: 0.8863 - val_recall_15: 0.8905 - val_f1_score: 0.8884 - 58s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.2836 - accuracy: 0.9017 - precision_15: 0.8802 - recall_15: 0.9261 - f1_score: 0.9025 - 4s/epoch - 155ms/step\n",
      "Run: 3\n",
      "Epoch 1/20\n",
      "26/26 - 69s - loss: 0.2669 - accuracy: 0.8846 - precision_16: 0.8853 - recall_16: 0.8824 - f1_score: 0.8839 - val_loss: 0.2674 - val_accuracy: 0.8887 - val_precision_16: 0.9194 - val_recall_16: 0.8472 - val_f1_score: 0.8818 - 69s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "26/26 - 58s - loss: 0.2518 - accuracy: 0.8905 - precision_16: 0.8955 - recall_16: 0.8829 - f1_score: 0.8891 - val_loss: 0.2720 - val_accuracy: 0.8929 - val_precision_16: 0.9050 - val_recall_16: 0.8734 - val_f1_score: 0.8889 - 58s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "26/26 - 58s - loss: 0.2323 - accuracy: 0.8994 - precision_16: 0.9000 - recall_16: 0.8974 - f1_score: 0.8987 - val_loss: 0.2770 - val_accuracy: 0.8715 - val_precision_16: 0.9289 - val_recall_16: 0.7991 - val_f1_score: 0.8592 - 58s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "26/26 - 58s - loss: 0.2335 - accuracy: 0.8936 - precision_16: 0.8941 - recall_16: 0.8917 - f1_score: 0.8929 - val_loss: 0.3115 - val_accuracy: 0.8758 - val_precision_16: 0.8548 - val_recall_16: 0.8996 - val_f1_score: 0.8766 - 58s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "26/26 - 58s - loss: 0.2185 - accuracy: 0.9025 - precision_16: 0.9010 - recall_16: 0.9032 - f1_score: 0.9021 - val_loss: 0.2975 - val_accuracy: 0.8672 - val_precision_16: 0.8711 - val_recall_16: 0.8559 - val_f1_score: 0.8634 - 58s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "26/26 - 58s - loss: 0.2124 - accuracy: 0.9044 - precision_16: 0.9008 - recall_16: 0.9077 - f1_score: 0.9043 - val_loss: 0.3066 - val_accuracy: 0.8544 - val_precision_16: 0.8546 - val_recall_16: 0.8472 - val_f1_score: 0.8509 - 58s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "26/26 - 58s - loss: 0.2049 - accuracy: 0.9109 - precision_16: 0.9078 - recall_16: 0.9137 - f1_score: 0.9108 - val_loss: 0.3141 - val_accuracy: 0.8630 - val_precision_16: 0.8873 - val_recall_16: 0.8253 - val_f1_score: 0.8552 - 58s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "26/26 - 57s - loss: 0.2022 - accuracy: 0.9112 - precision_16: 0.9058 - recall_16: 0.9168 - f1_score: 0.9113 - val_loss: 0.3153 - val_accuracy: 0.8587 - val_precision_16: 0.8756 - val_recall_16: 0.8297 - val_f1_score: 0.8520 - 57s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "26/26 - 58s - loss: 0.2045 - accuracy: 0.9062 - precision_16: 0.8967 - recall_16: 0.9170 - f1_score: 0.9067 - val_loss: 0.3688 - val_accuracy: 0.8437 - val_precision_16: 0.8645 - val_recall_16: 0.8079 - val_f1_score: 0.8352 - 58s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "26/26 - 58s - loss: 0.2058 - accuracy: 0.9027 - precision_16: 0.8928 - recall_16: 0.9142 - f1_score: 0.9034 - val_loss: 0.3189 - val_accuracy: 0.8694 - val_precision_16: 0.8889 - val_recall_16: 0.8384 - val_f1_score: 0.8629 - 58s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "26/26 - 58s - loss: 0.2025 - accuracy: 0.9139 - precision_16: 0.9093 - recall_16: 0.9185 - f1_score: 0.9139 - val_loss: 0.3240 - val_accuracy: 0.8565 - val_precision_16: 0.8320 - val_recall_16: 0.8865 - val_f1_score: 0.8584 - 58s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "26/26 - 58s - loss: 0.1913 - accuracy: 0.9134 - precision_16: 0.9045 - recall_16: 0.9235 - f1_score: 0.9139 - val_loss: 0.3293 - val_accuracy: 0.8458 - val_precision_16: 0.8520 - val_recall_16: 0.8297 - val_f1_score: 0.8407 - 58s/epoch - 2s/step\n",
      "INFO:tensorflow:Assets written to: ./exp1/models/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exp1/models/model3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "26/26 - 4s - loss: 0.2764 - accuracy: 0.8974 - precision_16: 0.8906 - recall_16: 0.9255 - f1_score: 0.9077 - 4s/epoch - 155ms/step\n",
      "Run: 4\n",
      "Epoch 1/20\n",
      "26/26 - 72s - loss: 0.2493 - accuracy: 0.8921 - precision_17: 0.8914 - recall_17: 0.8924 - f1_score: 0.8919 - val_loss: 0.2066 - val_accuracy: 0.9186 - val_precision_17: 0.9304 - val_recall_17: 0.9068 - val_f1_score: 0.9185 - 72s/epoch - 3s/step\n",
      "Epoch 2/20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "'''\n",
    "def get_shape(image):\n",
    "    return image.shape[0]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,shape, 1, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE*IMG_SIZE, 1])\n",
    "    return tf.reshape(image, [IMG_SIZE*IMG_SIZE, 1,3])\n",
    "'''\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = InceptionV3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.2\n",
    "  x = Dropout(0.2)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      '''\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      '''\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      #evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      #roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      #np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './exp1/images'\n",
    "dir_name = './exp1/models'\n",
    "file_name = './exp1/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./data_splits_obfus_aug_Exp2b\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94994a66-9ee1-427d-bb61-4b89ff0e1ef9",
   "metadata": {},
   "source": [
    "## Using a pretrained ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625a6647-1230-485f-bf42-524d58009343",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './mydex_trad/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 205\u001b[0m\n\u001b[1;32m    203\u001b[0m PATH_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./myhilbert_inter_resized/data_splits\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m CLASS_NAMES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodware\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalware\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 205\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 89\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Add a final sigmoid layer with 1 node for classification output\u001b[39;00m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 89\u001b[0m file_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m file_results\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mydex_trad/results'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = ResNet50(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.2\n",
    "  x = Dropout(0.2)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './mydex_trad/images'\n",
    "dir_name = './mydex_trad/models'\n",
    "file_name = './mydex_trad/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./myhilbert_inter_resized/data_splits\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271d0ec-8f30-4a02-bbe7-bfbba11ce98d",
   "metadata": {},
   "source": [
    "## Using a pretrained EfficientNetB0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa88a0fb-36b0-42dc-a862-c31f6d4fa40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Obtaining dependency information for efficientnet from https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl.metadata\n",
      "  Using cached efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
      "  Obtaining dependency information for keras-applications<=1.0.8,>=1.0.7 from https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl.metadata\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting scikit-image (from efficientnet)\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/33/29/1d696450464d6e13358d3ef185a1fb14a11181c5dab1eb2837c02be86373/scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.24.4)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (10.0.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for imageio>=2.27 from https://files.pythonhosted.org/packages/02/25/66533a8390e3763cf8254dee143dbf8a830391ea60d2762512ba7f9ddfbe/imageio-2.34.0-py3-none-any.whl.metadata\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/06/a3/68d17088a4f09565bc7341fd20490da8191ec4cddde479daaabbe07bb603/tifffile-2023.7.10-py3-none-any.whl.metadata\n",
      "  Using cached tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for PyWavelets>=1.1.1 from https://files.pythonhosted.org/packages/88/4b/b2b2a6f51e47c091c221bfde976a01a7e5f20e7e5e6341b2b9c4db73d2ed/PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from scikit-image->efficientnet) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image->efficientnet)\n",
      "  Obtaining dependency information for lazy_loader>=0.2 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Using cached efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Using cached tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, imageio, scikit-image, keras-applications, efficientnet\n",
      "Successfully installed PyWavelets-1.4.1 efficientnet-1.1.1 imageio-2.34.0 keras-applications-1.0.8 lazy_loader-0.4 scikit-image-0.21.0 tifffile-2023.7.10\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b667417-1de7-41ce-a159-68c42e61af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:32:02.628530: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 25s - loss: 2.4214 - accuracy: 0.6827 - precision: 0.6918 - recall: 0.6606 - f1_score: 0.6758 - val_loss: 0.5888 - val_accuracy: 0.7014 - val_precision: 0.6334 - val_recall: 0.9476 - val_f1_score: 0.7593 - 25s/epoch - 950ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.4564 - accuracy: 0.7851 - precision: 0.8038 - recall: 0.7552 - f1_score: 0.7787 - val_loss: 0.4062 - val_accuracy: 0.8297 - val_precision: 0.8439 - val_recall: 0.8065 - val_f1_score: 0.8247 - 6s/epoch - 229ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 6s - loss: 0.3881 - accuracy: 0.8259 - precision: 0.8497 - recall: 0.7925 - f1_score: 0.8201 - val_loss: 0.3806 - val_accuracy: 0.8437 - val_precision: 0.8542 - val_recall: 0.8266 - val_f1_score: 0.8402 - 6s/epoch - 229ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 6s - loss: 0.3625 - accuracy: 0.8415 - precision: 0.8631 - recall: 0.8123 - f1_score: 0.8369 - val_loss: 0.3632 - val_accuracy: 0.8677 - val_precision: 0.9174 - val_recall: 0.8065 - val_f1_score: 0.8584 - 6s/epoch - 241ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.3379 - accuracy: 0.8573 - precision: 0.8772 - recall: 0.8314 - f1_score: 0.8537 - val_loss: 0.3598 - val_accuracy: 0.8657 - val_precision: 0.9171 - val_recall: 0.8024 - val_f1_score: 0.8559 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.3286 - accuracy: 0.8629 - precision: 0.8883 - recall: 0.8305 - f1_score: 0.8585 - val_loss: 0.3462 - val_accuracy: 0.8657 - val_precision: 0.9132 - val_recall: 0.8065 - val_f1_score: 0.8565 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 6s - loss: 0.3146 - accuracy: 0.8664 - precision: 0.8864 - recall: 0.8410 - f1_score: 0.8631 - val_loss: 0.3441 - val_accuracy: 0.8737 - val_precision: 0.9224 - val_recall: 0.8145 - val_f1_score: 0.8651 - 6s/epoch - 229ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 6s - loss: 0.3067 - accuracy: 0.8764 - precision: 0.8985 - recall: 0.8492 - f1_score: 0.8731 - val_loss: 0.3369 - val_accuracy: 0.8798 - val_precision: 0.9196 - val_recall: 0.8306 - val_f1_score: 0.8729 - 6s/epoch - 230ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2951 - accuracy: 0.8764 - precision: 0.8972 - recall: 0.8507 - f1_score: 0.8733 - val_loss: 0.3350 - val_accuracy: 0.8737 - val_precision: 0.9224 - val_recall: 0.8145 - val_f1_score: 0.8651 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 6s - loss: 0.2828 - accuracy: 0.8851 - precision: 0.9023 - recall: 0.8641 - f1_score: 0.8828 - val_loss: 0.3261 - val_accuracy: 0.8818 - val_precision: 0.9276 - val_recall: 0.8266 - val_f1_score: 0.8742 - 6s/epoch - 229ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 6s - loss: 0.2831 - accuracy: 0.8853 - precision: 0.9062 - recall: 0.8601 - f1_score: 0.8825 - val_loss: 0.3326 - val_accuracy: 0.8898 - val_precision: 0.9251 - val_recall: 0.8468 - val_f1_score: 0.8842 - 6s/epoch - 230ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2770 - accuracy: 0.8883 - precision: 0.9071 - recall: 0.8656 - f1_score: 0.8859 - val_loss: 0.3271 - val_accuracy: 0.8798 - val_precision: 0.9352 - val_recall: 0.8145 - val_f1_score: 0.8707 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 6s - loss: 0.2655 - accuracy: 0.8922 - precision: 0.9103 - recall: 0.8705 - f1_score: 0.8900 - val_loss: 0.3195 - val_accuracy: 0.8918 - val_precision: 0.9369 - val_recall: 0.8387 - val_f1_score: 0.8851 - 6s/epoch - 228ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.2668 - accuracy: 0.8943 - precision: 0.9132 - recall: 0.8718 - f1_score: 0.8920 - val_loss: 0.3114 - val_accuracy: 0.8898 - val_precision: 0.9327 - val_recall: 0.8387 - val_f1_score: 0.8832 - 5s/epoch - 203ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2656 - accuracy: 0.8926 - precision: 0.9141 - recall: 0.8669 - f1_score: 0.8899 - val_loss: 0.3257 - val_accuracy: 0.8858 - val_precision: 0.8963 - val_recall: 0.8710 - val_f1_score: 0.8834 - 5s/epoch - 202ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 6s - loss: 0.2583 - accuracy: 0.8949 - precision: 0.9131 - recall: 0.8732 - f1_score: 0.8927 - val_loss: 0.3170 - val_accuracy: 0.9018 - val_precision: 0.9345 - val_recall: 0.8629 - val_f1_score: 0.8973 - 6s/epoch - 230ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2514 - accuracy: 0.8987 - precision: 0.9146 - recall: 0.8798 - f1_score: 0.8969 - val_loss: 0.3016 - val_accuracy: 0.8918 - val_precision: 0.9533 - val_recall: 0.8226 - val_f1_score: 0.8831 - 5s/epoch - 202ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2538 - accuracy: 0.8982 - precision: 0.9174 - recall: 0.8756 - f1_score: 0.8960 - val_loss: 0.3096 - val_accuracy: 0.9018 - val_precision: 0.9129 - val_recall: 0.8871 - val_f1_score: 0.8998 - 5s/epoch - 202ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.2430 - accuracy: 0.9003 - precision: 0.9181 - recall: 0.8794 - f1_score: 0.8983 - val_loss: 0.3042 - val_accuracy: 0.8938 - val_precision: 0.9372 - val_recall: 0.8427 - val_f1_score: 0.8875 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.2432 - accuracy: 0.9030 - precision: 0.9209 - recall: 0.8821 - f1_score: 0.9011 - val_loss: 0.3180 - val_accuracy: 0.8918 - val_precision: 0.9491 - val_recall: 0.8266 - val_f1_score: 0.8836 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.2627 - accuracy: 0.8920 - precision: 0.9283 - recall: 0.8449 - f1_score: 0.8846 - 1s/epoch - 60ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:34:49.934957: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.3824 - accuracy: 0.8395 - precision_1: 0.8452 - recall_1: 0.8322 - f1_score: 0.8386 - val_loss: 0.2527 - val_accuracy: 0.9058 - val_precision_1: 0.8727 - val_recall_1: 0.9472 - val_f1_score: 0.9084 - 21s/epoch - 800ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.2773 - accuracy: 0.8860 - precision_1: 0.9013 - recall_1: 0.8675 - f1_score: 0.8841 - val_loss: 0.2153 - val_accuracy: 0.9078 - val_precision_1: 0.9132 - val_recall_1: 0.8984 - val_f1_score: 0.9057 - 6s/epoch - 230ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 6s - loss: 0.2587 - accuracy: 0.8923 - precision_1: 0.9145 - recall_1: 0.8662 - f1_score: 0.8897 - val_loss: 0.2125 - val_accuracy: 0.9138 - val_precision_1: 0.9212 - val_recall_1: 0.9024 - val_f1_score: 0.9117 - 6s/epoch - 227ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2530 - accuracy: 0.8975 - precision_1: 0.9166 - recall_1: 0.8751 - f1_score: 0.8953 - val_loss: 0.2036 - val_accuracy: 0.9118 - val_precision_1: 0.9280 - val_recall_1: 0.8902 - val_f1_score: 0.9087 - 5s/epoch - 203ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2457 - accuracy: 0.9036 - precision_1: 0.9230 - recall_1: 0.8810 - f1_score: 0.9016 - val_loss: 0.2089 - val_accuracy: 0.9058 - val_precision_1: 0.9234 - val_recall_1: 0.8821 - val_f1_score: 0.9023 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2411 - accuracy: 0.9008 - precision_1: 0.9208 - recall_1: 0.8775 - f1_score: 0.8986 - val_loss: 0.2000 - val_accuracy: 0.9098 - val_precision_1: 0.9313 - val_recall_1: 0.8821 - val_f1_score: 0.9061 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 6s - loss: 0.2364 - accuracy: 0.9017 - precision_1: 0.9206 - recall_1: 0.8797 - f1_score: 0.8997 - val_loss: 0.2038 - val_accuracy: 0.9158 - val_precision_1: 0.9113 - val_recall_1: 0.9187 - val_f1_score: 0.9150 - 6s/epoch - 231ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.2369 - accuracy: 0.9060 - precision_1: 0.9248 - recall_1: 0.8844 - f1_score: 0.9041 - val_loss: 0.2163 - val_accuracy: 0.9098 - val_precision_1: 0.8941 - val_recall_1: 0.9268 - val_f1_score: 0.9102 - 5s/epoch - 203ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2353 - accuracy: 0.9055 - precision_1: 0.9226 - recall_1: 0.8857 - f1_score: 0.9038 - val_loss: 0.2041 - val_accuracy: 0.9098 - val_precision_1: 0.8972 - val_recall_1: 0.9228 - val_f1_score: 0.9098 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2337 - accuracy: 0.9045 - precision_1: 0.9218 - recall_1: 0.8844 - f1_score: 0.9027 - val_loss: 0.2129 - val_accuracy: 0.9138 - val_precision_1: 0.9109 - val_recall_1: 0.9146 - val_f1_score: 0.9128 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2365 - accuracy: 0.9031 - precision_1: 0.9210 - recall_1: 0.8824 - f1_score: 0.9013 - val_loss: 0.2070 - val_accuracy: 0.9138 - val_precision_1: 0.9143 - val_recall_1: 0.9106 - val_f1_score: 0.9124 - 5s/epoch - 202ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2290 - accuracy: 0.9052 - precision_1: 0.9196 - recall_1: 0.8886 - f1_score: 0.9038 - val_loss: 0.2007 - val_accuracy: 0.9158 - val_precision_1: 0.9359 - val_recall_1: 0.8902 - val_f1_score: 0.9125 - 5s/epoch - 202ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 6s - loss: 0.2230 - accuracy: 0.9079 - precision_1: 0.9222 - recall_1: 0.8915 - f1_score: 0.9066 - val_loss: 0.2239 - val_accuracy: 0.9178 - val_precision_1: 0.8868 - val_recall_1: 0.9553 - val_f1_score: 0.9198 - 6s/epoch - 230ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 6s - loss: 0.2301 - accuracy: 0.9077 - precision_1: 0.9218 - recall_1: 0.8915 - f1_score: 0.9064 - val_loss: 0.2027 - val_accuracy: 0.9198 - val_precision_1: 0.9402 - val_recall_1: 0.8943 - val_f1_score: 0.9167 - 6s/epoch - 229ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2230 - accuracy: 0.9080 - precision_1: 0.9275 - recall_1: 0.8857 - f1_score: 0.9061 - val_loss: 0.2151 - val_accuracy: 0.9118 - val_precision_1: 0.9139 - val_recall_1: 0.9065 - val_f1_score: 0.9102 - 5s/epoch - 203ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.2243 - accuracy: 0.9072 - precision_1: 0.9266 - recall_1: 0.8850 - f1_score: 0.9053 - val_loss: 0.2267 - val_accuracy: 0.9078 - val_precision_1: 0.8876 - val_recall_1: 0.9309 - val_f1_score: 0.9087 - 5s/epoch - 203ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2251 - accuracy: 0.9088 - precision_1: 0.9250 - recall_1: 0.8901 - f1_score: 0.9073 - val_loss: 0.2123 - val_accuracy: 0.9198 - val_precision_1: 0.9256 - val_recall_1: 0.9106 - val_f1_score: 0.9180 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2297 - accuracy: 0.9072 - precision_1: 0.9199 - recall_1: 0.8926 - f1_score: 0.9061 - val_loss: 0.1938 - val_accuracy: 0.9158 - val_precision_1: 0.9359 - val_recall_1: 0.8902 - val_f1_score: 0.9125 - 5s/epoch - 203ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.2132 - accuracy: 0.9140 - precision_1: 0.9314 - recall_1: 0.8944 - f1_score: 0.9125 - val_loss: 0.2027 - val_accuracy: 0.9138 - val_precision_1: 0.9394 - val_recall_1: 0.8821 - val_f1_score: 0.9099 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.2196 - accuracy: 0.9129 - precision_1: 0.9294 - recall_1: 0.8941 - f1_score: 0.9114 - val_loss: 0.2046 - val_accuracy: 0.9078 - val_precision_1: 0.9098 - val_recall_1: 0.9024 - val_f1_score: 0.9061 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1575 - accuracy: 0.9520 - precision_1: 0.9660 - recall_1: 0.9342 - f1_score: 0.9498 - 919ms/epoch - 37ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:37:26.340784: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 23s - loss: 0.2456 - accuracy: 0.8998 - precision_2: 0.9162 - recall_2: 0.8811 - f1_score: 0.8983 - val_loss: 0.1662 - val_accuracy: 0.9459 - val_precision_2: 0.9390 - val_recall_2: 0.9506 - val_f1_score: 0.9448 - 23s/epoch - 868ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 5s - loss: 0.2124 - accuracy: 0.9137 - precision_2: 0.9273 - recall_2: 0.8986 - f1_score: 0.9127 - val_loss: 0.1689 - val_accuracy: 0.9359 - val_precision_2: 0.9607 - val_recall_2: 0.9053 - val_f1_score: 0.9322 - 5s/epoch - 203ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.2100 - accuracy: 0.9124 - precision_2: 0.9317 - recall_2: 0.8908 - f1_score: 0.9108 - val_loss: 0.1725 - val_accuracy: 0.9419 - val_precision_2: 0.9213 - val_recall_2: 0.9630 - val_f1_score: 0.9416 - 5s/epoch - 203ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2088 - accuracy: 0.9137 - precision_2: 0.9309 - recall_2: 0.8946 - f1_score: 0.9124 - val_loss: 0.1667 - val_accuracy: 0.9419 - val_precision_2: 0.9612 - val_recall_2: 0.9177 - val_f1_score: 0.9389 - 5s/epoch - 203ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2056 - accuracy: 0.9171 - precision_2: 0.9359 - recall_2: 0.8963 - f1_score: 0.9157 - val_loss: 0.1810 - val_accuracy: 0.9379 - val_precision_2: 0.9454 - val_recall_2: 0.9259 - val_f1_score: 0.9356 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2097 - accuracy: 0.9128 - precision_2: 0.9289 - recall_2: 0.8948 - f1_score: 0.9116 - val_loss: 0.1669 - val_accuracy: 0.9359 - val_precision_2: 0.9528 - val_recall_2: 0.9136 - val_f1_score: 0.9328 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.2054 - accuracy: 0.9159 - precision_2: 0.9356 - recall_2: 0.8941 - f1_score: 0.9144 - val_loss: 0.1688 - val_accuracy: 0.9419 - val_precision_2: 0.9612 - val_recall_2: 0.9177 - val_f1_score: 0.9389 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.2087 - accuracy: 0.9155 - precision_2: 0.9351 - recall_2: 0.8937 - f1_score: 0.9139 - val_loss: 0.1806 - val_accuracy: 0.9379 - val_precision_2: 0.9492 - val_recall_2: 0.9218 - val_f1_score: 0.9353 - 5s/epoch - 203ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 6s - loss: 0.2077 - accuracy: 0.9144 - precision_2: 0.9344 - recall_2: 0.8921 - f1_score: 0.9128 - val_loss: 0.1599 - val_accuracy: 0.9499 - val_precision_2: 0.9467 - val_recall_2: 0.9506 - val_f1_score: 0.9487 - 6s/epoch - 229ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2085 - accuracy: 0.9166 - precision_2: 0.9343 - recall_2: 0.8970 - f1_score: 0.9153 - val_loss: 0.1757 - val_accuracy: 0.9479 - val_precision_2: 0.9465 - val_recall_2: 0.9465 - val_f1_score: 0.9465 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2086 - accuracy: 0.9159 - precision_2: 0.9326 - recall_2: 0.8975 - f1_score: 0.9147 - val_loss: 0.1663 - val_accuracy: 0.9499 - val_precision_2: 0.9504 - val_recall_2: 0.9465 - val_f1_score: 0.9485 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.2031 - accuracy: 0.9179 - precision_2: 0.9301 - recall_2: 0.9045 - f1_score: 0.9171 - val_loss: 0.1710 - val_accuracy: 0.9419 - val_precision_2: 0.9534 - val_recall_2: 0.9259 - val_f1_score: 0.9395 - 5s/epoch - 204ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.2028 - accuracy: 0.9214 - precision_2: 0.9397 - recall_2: 0.9012 - f1_score: 0.9201 - val_loss: 0.1596 - val_accuracy: 0.9459 - val_precision_2: 0.9463 - val_recall_2: 0.9424 - val_f1_score: 0.9443 - 5s/epoch - 203ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.1963 - accuracy: 0.9203 - precision_2: 0.9390 - recall_2: 0.8997 - f1_score: 0.9189 - val_loss: 0.1749 - val_accuracy: 0.9419 - val_precision_2: 0.9180 - val_recall_2: 0.9671 - val_f1_score: 0.9419 - 5s/epoch - 203ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 5s - loss: 0.2064 - accuracy: 0.9135 - precision_2: 0.9304 - recall_2: 0.8946 - f1_score: 0.9121 - val_loss: 0.1860 - val_accuracy: 0.9419 - val_precision_2: 0.9421 - val_recall_2: 0.9383 - val_f1_score: 0.9402 - 5s/epoch - 203ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.2071 - accuracy: 0.9146 - precision_2: 0.9322 - recall_2: 0.8950 - f1_score: 0.9132 - val_loss: 0.1685 - val_accuracy: 0.9439 - val_precision_2: 0.9461 - val_recall_2: 0.9383 - val_f1_score: 0.9421 - 5s/epoch - 204ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2054 - accuracy: 0.9174 - precision_2: 0.9372 - recall_2: 0.8955 - f1_score: 0.9158 - val_loss: 0.1920 - val_accuracy: 0.9359 - val_precision_2: 0.9137 - val_recall_2: 0.9588 - val_f1_score: 0.9357 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2140 - accuracy: 0.9104 - precision_2: 0.9336 - recall_2: 0.8844 - f1_score: 0.9083 - val_loss: 0.1913 - val_accuracy: 0.9339 - val_precision_2: 0.9200 - val_recall_2: 0.9465 - val_f1_score: 0.9331 - 5s/epoch - 204ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.1970 - accuracy: 0.9197 - precision_2: 0.9377 - recall_2: 0.8999 - f1_score: 0.9184 - val_loss: 0.1727 - val_accuracy: 0.9359 - val_precision_2: 0.9528 - val_recall_2: 0.9136 - val_f1_score: 0.9328 - 5s/epoch - 209ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1546 - accuracy: 0.9460 - precision_2: 0.9605 - recall_2: 0.9241 - f1_score: 0.9419 - 963ms/epoch - 39ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:39:55.992160: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.2199 - accuracy: 0.9111 - precision_3: 0.9260 - recall_3: 0.8941 - f1_score: 0.9097 - val_loss: 0.1653 - val_accuracy: 0.9359 - val_precision_3: 0.9364 - val_recall_3: 0.9286 - val_f1_score: 0.9325 - 21s/epoch - 823ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.2047 - accuracy: 0.9176 - precision_3: 0.9340 - recall_3: 0.8990 - f1_score: 0.9162 - val_loss: 0.1479 - val_accuracy: 0.9379 - val_precision_3: 0.9641 - val_recall_3: 0.9034 - val_f1_score: 0.9328 - 6s/epoch - 233ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.1916 - accuracy: 0.9259 - precision_3: 0.9430 - recall_3: 0.9070 - f1_score: 0.9246 - val_loss: 0.1561 - val_accuracy: 0.9279 - val_precision_3: 0.9633 - val_recall_3: 0.8824 - val_f1_score: 0.9211 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.1992 - accuracy: 0.9193 - precision_3: 0.9351 - recall_3: 0.9014 - f1_score: 0.9179 - val_loss: 0.1707 - val_accuracy: 0.9238 - val_precision_3: 0.9464 - val_recall_3: 0.8908 - val_f1_score: 0.9177 - 5s/epoch - 202ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.2045 - accuracy: 0.9166 - precision_3: 0.9339 - recall_3: 0.8970 - f1_score: 0.9151 - val_loss: 0.1738 - val_accuracy: 0.9238 - val_precision_3: 0.9545 - val_recall_3: 0.8824 - val_f1_score: 0.9170 - 5s/epoch - 203ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2017 - accuracy: 0.9191 - precision_3: 0.9371 - recall_3: 0.8990 - f1_score: 0.9176 - val_loss: 0.1769 - val_accuracy: 0.9138 - val_precision_3: 0.9621 - val_recall_3: 0.8529 - val_f1_score: 0.9042 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.2025 - accuracy: 0.9139 - precision_3: 0.9401 - recall_3: 0.8845 - f1_score: 0.9115 - val_loss: 0.1683 - val_accuracy: 0.9218 - val_precision_3: 0.9462 - val_recall_3: 0.8866 - val_f1_score: 0.9154 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1944 - accuracy: 0.9219 - precision_3: 0.9403 - recall_3: 0.9014 - f1_score: 0.9204 - val_loss: 0.1762 - val_accuracy: 0.9198 - val_precision_3: 0.9806 - val_recall_3: 0.8487 - val_f1_score: 0.9099 - 5s/epoch - 202ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.1976 - accuracy: 0.9146 - precision_3: 0.9364 - recall_3: 0.8899 - f1_score: 0.9126 - val_loss: 0.1738 - val_accuracy: 0.9319 - val_precision_3: 0.9474 - val_recall_3: 0.9076 - val_f1_score: 0.9270 - 5s/epoch - 202ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.2077 - accuracy: 0.9126 - precision_3: 0.9399 - recall_3: 0.8819 - f1_score: 0.9100 - val_loss: 0.1719 - val_accuracy: 0.9279 - val_precision_3: 0.9720 - val_recall_3: 0.8739 - val_f1_score: 0.9204 - 5s/epoch - 202ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.2055 - accuracy: 0.9132 - precision_3: 0.9381 - recall_3: 0.8852 - f1_score: 0.9109 - val_loss: 0.1671 - val_accuracy: 0.9319 - val_precision_3: 0.9554 - val_recall_3: 0.8992 - val_f1_score: 0.9264 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1994 - accuracy: 0.9200 - precision_3: 0.9435 - recall_3: 0.8939 - f1_score: 0.9180 - val_loss: 0.1772 - val_accuracy: 0.9238 - val_precision_3: 0.9464 - val_recall_3: 0.8908 - val_f1_score: 0.9177 - 5s/epoch - 207ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1427 - accuracy: 0.9380 - precision_3: 0.9587 - recall_3: 0.9170 - f1_score: 0.9374 - 953ms/epoch - 38ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:41:48.661441: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.2011 - accuracy: 0.9207 - precision_4: 0.9365 - recall_4: 0.9025 - f1_score: 0.9192 - val_loss: 0.1522 - val_accuracy: 0.9379 - val_precision_4: 0.9422 - val_recall_4: 0.9217 - val_f1_score: 0.9319 - 21s/epoch - 820ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 6s - loss: 0.1961 - accuracy: 0.9193 - precision_4: 0.9329 - recall_4: 0.9034 - f1_score: 0.9179 - val_loss: 0.1568 - val_accuracy: 0.9399 - val_precision_4: 0.9808 - val_recall_4: 0.8870 - val_f1_score: 0.9315 - 6s/epoch - 231ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.2024 - accuracy: 0.9197 - precision_4: 0.9384 - recall_4: 0.8983 - f1_score: 0.9179 - val_loss: 0.1511 - val_accuracy: 0.9359 - val_precision_4: 0.9342 - val_recall_4: 0.9261 - val_f1_score: 0.9301 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 5s - loss: 0.2029 - accuracy: 0.9181 - precision_4: 0.9380 - recall_4: 0.8954 - f1_score: 0.9162 - val_loss: 0.1605 - val_accuracy: 0.9319 - val_precision_4: 0.9667 - val_recall_4: 0.8826 - val_f1_score: 0.9227 - 5s/epoch - 202ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.1988 - accuracy: 0.9217 - precision_4: 0.9372 - recall_4: 0.9039 - f1_score: 0.9202 - val_loss: 0.1658 - val_accuracy: 0.9299 - val_precision_4: 0.9710 - val_recall_4: 0.8739 - val_f1_score: 0.9199 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.2059 - accuracy: 0.9156 - precision_4: 0.9326 - recall_4: 0.8958 - f1_score: 0.9138 - val_loss: 0.1713 - val_accuracy: 0.9319 - val_precision_4: 0.9623 - val_recall_4: 0.8870 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.1968 - accuracy: 0.9185 - precision_4: 0.9330 - recall_4: 0.9016 - f1_score: 0.9170 - val_loss: 0.1663 - val_accuracy: 0.9259 - val_precision_4: 0.9177 - val_recall_4: 0.9217 - val_f1_score: 0.9197 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1962 - accuracy: 0.9174 - precision_4: 0.9308 - recall_4: 0.9016 - f1_score: 0.9160 - val_loss: 0.1950 - val_accuracy: 0.9238 - val_precision_4: 0.9848 - val_recall_4: 0.8478 - val_f1_score: 0.9112 - 5s/epoch - 202ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.2050 - accuracy: 0.9108 - precision_4: 0.9301 - recall_4: 0.8883 - f1_score: 0.9087 - val_loss: 0.1590 - val_accuracy: 0.9399 - val_precision_4: 0.9717 - val_recall_4: 0.8957 - val_f1_score: 0.9321 - 5s/epoch - 203ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 6s - loss: 0.2023 - accuracy: 0.9176 - precision_4: 0.9351 - recall_4: 0.8974 - f1_score: 0.9158 - val_loss: 0.1557 - val_accuracy: 0.9419 - val_precision_4: 0.9467 - val_recall_4: 0.9261 - val_f1_score: 0.9363 - 6s/epoch - 231ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.1953 - accuracy: 0.9174 - precision_4: 0.9356 - recall_4: 0.8963 - f1_score: 0.9155 - val_loss: 0.1625 - val_accuracy: 0.9339 - val_precision_4: 0.9191 - val_recall_4: 0.9391 - val_f1_score: 0.9290 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1887 - accuracy: 0.9234 - precision_4: 0.9356 - recall_4: 0.9092 - f1_score: 0.9222 - val_loss: 0.1615 - val_accuracy: 0.9399 - val_precision_4: 0.9464 - val_recall_4: 0.9217 - val_f1_score: 0.9339 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.1881 - accuracy: 0.9231 - precision_4: 0.9429 - recall_4: 0.9007 - f1_score: 0.9213 - val_loss: 0.1619 - val_accuracy: 0.9299 - val_precision_4: 0.9333 - val_recall_4: 0.9130 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 6s - loss: 0.1921 - accuracy: 0.9236 - precision_4: 0.9397 - recall_4: 0.9052 - f1_score: 0.9221 - val_loss: 0.1553 - val_accuracy: 0.9439 - val_precision_4: 0.9676 - val_recall_4: 0.9087 - val_f1_score: 0.9372 - 6s/epoch - 231ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 6s - loss: 0.1982 - accuracy: 0.9196 - precision_4: 0.9380 - recall_4: 0.8985 - f1_score: 0.9178 - val_loss: 0.1489 - val_accuracy: 0.9479 - val_precision_4: 0.9679 - val_recall_4: 0.9174 - val_f1_score: 0.9420 - 6s/epoch - 230ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 5s - loss: 0.1949 - accuracy: 0.9207 - precision_4: 0.9383 - recall_4: 0.9005 - f1_score: 0.9190 - val_loss: 0.1604 - val_accuracy: 0.9319 - val_precision_4: 0.9623 - val_recall_4: 0.8870 - val_f1_score: 0.9231 - 5s/epoch - 203ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 5s - loss: 0.2076 - accuracy: 0.9136 - precision_4: 0.9370 - recall_4: 0.8867 - f1_score: 0.9111 - val_loss: 0.1837 - val_accuracy: 0.9138 - val_precision_4: 0.8848 - val_recall_4: 0.9348 - val_f1_score: 0.9091 - 5s/epoch - 203ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 5s - loss: 0.2049 - accuracy: 0.9130 - precision_4: 0.9322 - recall_4: 0.8907 - f1_score: 0.9110 - val_loss: 0.1641 - val_accuracy: 0.9359 - val_precision_4: 0.9459 - val_recall_4: 0.9130 - val_f1_score: 0.9292 - 5s/epoch - 203ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 5s - loss: 0.1966 - accuracy: 0.9175 - precision_4: 0.9359 - recall_4: 0.8963 - f1_score: 0.9156 - val_loss: 0.1581 - val_accuracy: 0.9339 - val_precision_4: 0.9539 - val_recall_4: 0.9000 - val_f1_score: 0.9262 - 5s/epoch - 203ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 5s - loss: 0.1971 - accuracy: 0.9156 - precision_4: 0.9364 - recall_4: 0.8916 - f1_score: 0.9135 - val_loss: 0.1772 - val_accuracy: 0.9339 - val_precision_4: 0.9668 - val_recall_4: 0.8870 - val_f1_score: 0.9252 - 5s/epoch - 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1708 - accuracy: 0.9380 - precision_4: 0.9582 - recall_4: 0.9265 - f1_score: 0.9421 - 976ms/epoch - 39ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1734bbd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1734bbd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 6\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:44:25.703050: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 21s - loss: 0.1961 - accuracy: 0.9183 - precision_5: 0.9297 - recall_5: 0.9047 - f1_score: 0.9170 - val_loss: 0.1335 - val_accuracy: 0.9539 - val_precision_5: 0.9646 - val_recall_5: 0.9459 - val_f1_score: 0.9552 - 21s/epoch - 796ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 5s - loss: 0.1887 - accuracy: 0.9236 - precision_5: 0.9411 - recall_5: 0.9036 - f1_score: 0.9219 - val_loss: 0.1375 - val_accuracy: 0.9539 - val_precision_5: 0.9720 - val_recall_5: 0.9382 - val_f1_score: 0.9548 - 5s/epoch - 202ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 5s - loss: 0.1854 - accuracy: 0.9215 - precision_5: 0.9429 - recall_5: 0.8971 - f1_score: 0.9194 - val_loss: 0.1326 - val_accuracy: 0.9459 - val_precision_5: 0.9715 - val_recall_5: 0.9228 - val_f1_score: 0.9465 - 5s/epoch - 202ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 6s - loss: 0.1836 - accuracy: 0.9255 - precision_5: 0.9456 - recall_5: 0.9027 - f1_score: 0.9237 - val_loss: 0.1418 - val_accuracy: 0.9599 - val_precision_5: 0.9723 - val_recall_5: 0.9498 - val_f1_score: 0.9609 - 6s/epoch - 229ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 5s - loss: 0.1907 - accuracy: 0.9243 - precision_5: 0.9424 - recall_5: 0.9036 - f1_score: 0.9226 - val_loss: 0.1342 - val_accuracy: 0.9579 - val_precision_5: 0.9760 - val_recall_5: 0.9421 - val_f1_score: 0.9587 - 5s/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 5s - loss: 0.1881 - accuracy: 0.9195 - precision_5: 0.9391 - recall_5: 0.8969 - f1_score: 0.9175 - val_loss: 0.1359 - val_accuracy: 0.9579 - val_precision_5: 0.9798 - val_recall_5: 0.9382 - val_f1_score: 0.9586 - 5s/epoch - 202ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 5s - loss: 0.1805 - accuracy: 0.9260 - precision_5: 0.9465 - recall_5: 0.9029 - f1_score: 0.9242 - val_loss: 0.1498 - val_accuracy: 0.9519 - val_precision_5: 0.9572 - val_recall_5: 0.9498 - val_f1_score: 0.9535 - 5s/epoch - 203ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 5s - loss: 0.1718 - accuracy: 0.9305 - precision_5: 0.9454 - recall_5: 0.9136 - f1_score: 0.9292 - val_loss: 0.1336 - val_accuracy: 0.9499 - val_precision_5: 0.9643 - val_recall_5: 0.9382 - val_f1_score: 0.9511 - 5s/epoch - 204ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 5s - loss: 0.1721 - accuracy: 0.9280 - precision_5: 0.9453 - recall_5: 0.9085 - f1_score: 0.9265 - val_loss: 0.1399 - val_accuracy: 0.9539 - val_precision_5: 0.9609 - val_recall_5: 0.9498 - val_f1_score: 0.9553 - 5s/epoch - 202ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 5s - loss: 0.1741 - accuracy: 0.9275 - precision_5: 0.9448 - recall_5: 0.9078 - f1_score: 0.9259 - val_loss: 0.1357 - val_accuracy: 0.9559 - val_precision_5: 0.9647 - val_recall_5: 0.9498 - val_f1_score: 0.9572 - 5s/epoch - 203ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 5s - loss: 0.1789 - accuracy: 0.9256 - precision_5: 0.9440 - recall_5: 0.9047 - f1_score: 0.9239 - val_loss: 0.1300 - val_accuracy: 0.9579 - val_precision_5: 0.9722 - val_recall_5: 0.9459 - val_f1_score: 0.9589 - 5s/epoch - 203ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 5s - loss: 0.1776 - accuracy: 0.9288 - precision_5: 0.9468 - recall_5: 0.9085 - f1_score: 0.9273 - val_loss: 0.1444 - val_accuracy: 0.9519 - val_precision_5: 0.9644 - val_recall_5: 0.9421 - val_f1_score: 0.9531 - 5s/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 5s - loss: 0.1798 - accuracy: 0.9253 - precision_5: 0.9469 - recall_5: 0.9009 - f1_score: 0.9233 - val_loss: 0.1462 - val_accuracy: 0.9439 - val_precision_5: 0.9529 - val_recall_5: 0.9382 - val_f1_score: 0.9455 - 5s/epoch - 202ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 5s - loss: 0.1799 - accuracy: 0.9246 - precision_5: 0.9478 - recall_5: 0.8984 - f1_score: 0.9225 - val_loss: 0.1489 - val_accuracy: 0.9479 - val_precision_5: 0.9605 - val_recall_5: 0.9382 - val_f1_score: 0.9492 - 5s/epoch - 207ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_ds_trad_res/models/model6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "25/25 - 1s - loss: 0.1594 - accuracy: 0.9480 - precision_5: 0.9583 - recall_5: 0.9350 - f1_score: 0.9465 - 914ms/epoch - 37ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f17ff6ce670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f17ff6ce670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Run: 7\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:46:33.559844: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-17 04:46:49.749838: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at save_restore_v2_ops.cc:138 : RESOURCE_EXHAUSTED: all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__SaveV2_dtypes_324_device_/job:localhost/replica:0/task:0/device:CPU:0}} all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 205\u001b[0m\n\u001b[1;32m    203\u001b[0m PATH_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data_splits2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m CLASS_NAMES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodware\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalware\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 205\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_FILES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 159\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)\u001b[0m\n\u001b[1;32m    156\u001b[0m path_save_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m    158\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 159\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time()\u001b[38;5;241m-\u001b[39mstart\n\u001b[1;32m    161\u001b[0m training_time_list\u001b[38;5;241m.\u001b[39mappend(train_time)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__SaveV2_dtypes_324_device_/job:localhost/replica:0/task:0/device:CPU:0}} all_ds_trad_res/models/cp7_temp/part-00000-of-00001.data-00000-of-00001.tempstate9992209287203798072; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "import efficientnet.keras as efn\n",
    "from keras.layers import Dropout\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "python_random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import argparse\n",
    "\n",
    "def parseargs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", help=\"The path to the directory that contains malware and goodware image folders\", type=str, required=True)\n",
    "    parser.add_argument(\"-d\", \"--dir\", help=\"The name of the directory where to save the model\", type=str, required=True)\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"The name of the file where to save the results of the evaluation\", type=str, required=True) \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == 'goodware':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]\n",
    "\n",
    "\n",
    "def get_image(path_img):\n",
    "    image = np.asarray(Image.open(path_img).convert('RGB'))\n",
    "    #image = np.asarray(Image.open(path_img))\n",
    "    image = tf.convert_to_tensor(image, dtype_hint=None, name=None)\n",
    "    return image\n",
    "\n",
    "def get_shape(image):\n",
    "    #print(image.shape)\n",
    "    return image.shape[1]\n",
    "\n",
    "def decode_img(path_img):\n",
    "    image = tf.numpy_function(get_image, [path_img], tf.uint8)\n",
    "    shape = tf.numpy_function(get_shape, [image], tf.int64)\n",
    "    image = tf.reshape(image, [1,IMG_SIZE, shape, 3])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return tf.reshape(image, [IMG_SIZE, IMG_SIZE,3])\n",
    "    #return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "    \n",
    "def main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES):\n",
    "  recall_list, precision_list, accuracy_list, f1_list, roc_auc_list, training_time_list = [], [], [], [], [], []\n",
    "\n",
    "  model_architecture = efn.EfficientNetB0(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')  \n",
    "  for layer in model_architecture.layers:\n",
    "    layer.trainable = False\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = Flatten()(model_architecture.output)\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  # Add a dropout rate of 0.5\n",
    "  x = Dropout(0.5)(x)\n",
    "  # Add a final sigmoid layer with 1 node for classification output\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  \n",
    "    \n",
    "  file_results = open(file_name, \"w\")\n",
    "  file_results.write(\"Scores of the performance evaluation are: Accuracy, Precision, Recall, F1-score, ROC-AUC, Training time\\n\")\n",
    "  for i in range(1, 11):\n",
    "      file_results.write(\"Run: %d \\n\" % i)\n",
    "      print(\"Run: %d\" % i)\n",
    "      with open(os.path.join(PATH_FILES, \"train\"+str(i)+\".txt\")) as f:\n",
    "          train_hashes = f.read().splitlines()\n",
    "          train_imgs = [os.path.join(path_images, image_hash) for image_hash in train_hashes]\n",
    "          #print(train_imgs)\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"valid\"+str(i)+\".txt\")) as f:\n",
    "          valid_hashes = f.read().splitlines()\n",
    "          valid_imgs = [os.path.join(path_images, image_hash) for image_hash in valid_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      with open(os.path.join(PATH_FILES, \"test\"+str(i)+\".txt\")) as f:\n",
    "          test_hashes = f.read().splitlines()\n",
    "          test_imgs = [os.path.join(path_images, image_hash) for image_hash in test_hashes]\n",
    "      f.close()\n",
    "      \n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "      #for element in train_dataset:\n",
    "          #print(element)\n",
    "\n",
    "      train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_train = len(train_imgs)\n",
    "      batch_train = length_train//BATCH_SIZE\n",
    "      train_dataset = train_dataset.cache()\n",
    "      train_dataset = train_dataset.shuffle(buffer_size=length_train, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      train_dataset = train_dataset.batch(batch_train)\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      valid_dataset = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
    "      valid_dataset = valid_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_valid = len(valid_imgs)\n",
    "      batch_valid = length_valid//BATCH_SIZE\n",
    "      valid_dataset = valid_dataset.cache()\n",
    "      valid_dataset = valid_dataset.shuffle(buffer_size=length_valid, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      valid_dataset = valid_dataset.batch(batch_valid)\n",
    "      valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "      test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "      test_dataset = test_dataset.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "      length_test = len(test_imgs)\n",
    "      batch_test = length_test//BATCH_SIZE\n",
    "      test_dataset = test_dataset.cache()\n",
    "      test_dataset = test_dataset.shuffle(buffer_size=length_test, seed = random_seed, reshuffle_each_iteration=False)\n",
    "      test_dataset = test_dataset.batch(batch_test)\n",
    "      test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      \n",
    "      #model = keras.models.clone_model(model_architecture)\n",
    "      model = tf.keras.models.Model(model_architecture.input, x)\n",
    "      model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=['accuracy',\n",
    "                             tf.keras.metrics.Precision(),\n",
    "                             tf.keras.metrics.Recall(),\n",
    "                             tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.5)])\n",
    "       \n",
    "      #a callback function which stops the training once the network hits a predefined accuracy level.                      \n",
    "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "      cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dir_name, 'cp'+str(i)), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode='max',\n",
    "                                                       save_best_only=True)\n",
    "      path_save_model = os.path.join(dir_name, 'model'+str(i))\n",
    "\n",
    "      start = time()\n",
    "      model.fit(train_dataset, shuffle=True, validation_data = valid_dataset, epochs=EPOCHS, callbacks=[es_callback, cp_callback], verbose=2)\n",
    "      train_time = time()-start\n",
    "      training_time_list.append(train_time)\n",
    "      model.save(path_save_model)\n",
    "      print(\"Evaluate the model\")\n",
    "      evaluation_scores = model.evaluate(test_dataset, verbose=2)\n",
    "      #y_valid_pred = model.predict(valid_dataset)\n",
    "      #y_test_pred = model.predict(test_dataset)\n",
    "      #val_roc_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "      for image_batch, labels_batch in test_dataset:\n",
    "        x_test = image_batch.numpy()\n",
    "        y_test = labels_batch.numpy()\n",
    "      y_test_pred = model.predict(x_test)\n",
    "      test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "      #print(\"AUC = \", test_roc_auc)\n",
    "      #print(y_test_pred)\n",
    "      #print(y_test)\n",
    "      evaluation_scores.append(test_roc_auc)\n",
    "      evaluation_scores.append(train_time)\n",
    "      file_results.write(\"%s  \\n\" % evaluation_scores[1:])\n",
    "      file_results.write(\"#\"*50+\"\\n\")\n",
    "      accuracy_list.append(evaluation_scores[1])\n",
    "      precision_list.append(evaluation_scores[2])\n",
    "      recall_list.append(evaluation_scores[3])\n",
    "      f1_list.append(evaluation_scores[4])\n",
    "      roc_auc_list.append(test_roc_auc)\n",
    "  #print(roc_auc_list)\n",
    "  file_results.write(\"Average scores: %f %f %f %f %f %f\" % (np.mean(accuracy_list), \n",
    "                                                      np.mean(precision_list), \n",
    "                                                      np.mean(recall_list), \n",
    "                                                      np.mean(f1_list),\n",
    "                                                      np.mean(roc_auc_list),\n",
    "                                                      np.sum(training_time_list)))\n",
    "  \n",
    "  file_results.close()\n",
    "\n",
    "#current_directory = os. getcwd()\n",
    "path_images = './all_ds_trad_res/images'\n",
    "dir_name = './all_ds_trad_res/models'\n",
    "file_name = './all_ds_trad_res/results' \n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 25\n",
    "IMG_SIZE = 128\n",
    "PATH_FILES = \"./data_splits2\"\n",
    "CLASS_NAMES = ['goodware', 'malware']\n",
    "main(path_images, dir_name, file_name, CHANNELS, EPOCHS, BATCH_SIZE, IMG_SIZE, PATH_FILES, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446d1fc-846d-4932-a199-307de4328710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
