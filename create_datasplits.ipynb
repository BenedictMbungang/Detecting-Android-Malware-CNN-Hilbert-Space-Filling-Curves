{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf24b6fa-ae03-4eda-90ba-c88ff7cbee2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.21.0\n",
      "  Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from tensorflow-addons==0.21.0) (23.2)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.21.0)\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.21.0\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b7a70-f377-412d-9866-a59effd52968",
   "metadata": {},
   "source": [
    "## Create data splits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1644168-baa8-4cbc-80c0-b302fe4973eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware image count =  7068\n",
      "goodware image count =  9681\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#import shutil\n",
    "import random\n",
    "\n",
    "random.seed(7818901)\n",
    "#print(os. getcwd())\n",
    "#rdir=os. getcwd()\n",
    "# Source and destination directories\n",
    "malware_source_dir = \"./exp1/images/malware\"\n",
    "#malware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/malware\"\n",
    "goodware_source_dir = \"./exp1/images/goodware\"\n",
    "#goodware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/goodware\"\n",
    "PATH_FILES = \"./data_splits_obfus_aug1/all.txt\"\n",
    "PATH_FILES1 = \"./data_splits_obfus_aug1/all_shuffle.txt\"\n",
    "\n",
    "malcount=0\n",
    "goodcount=0\n",
    "for path in os.listdir(malware_source_dir):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(malware_source_dir, path)):\n",
    "        malcount += 1\n",
    "print('malware image count = ', malcount)         \n",
    "for path in os.listdir(goodware_source_dir):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(goodware_source_dir, path)):\n",
    "        goodcount += 1\n",
    "print('goodware image count = ', goodcount) \n",
    "\n",
    "# Randomly select files from source directory  file\n",
    "files = random.sample(os.listdir(malware_source_dir), k=4672)\n",
    "files1 = random.sample(os.listdir(goodware_source_dir), k=4672)\n",
    "\n",
    "\n",
    "# Create text file with all images:\n",
    "with open(PATH_FILES, \"a\") as f:\n",
    "    for file in files:\n",
    "      #malware_full_source = os.path.join(malware_source_dir, file)\n",
    "      data = malware_source_dir.split(os.path.sep)[-1]+os.path.sep+file\n",
    "      f.write(data)\n",
    "      f.write('\\n')\n",
    "    for file in files1:\n",
    "      #malware_full_source = os.path.join(malware_source_dir, file)\n",
    "      data = goodware_source_dir.split(os.path.sep)[-1]+os.path.sep+file\n",
    "      f.write(data)\n",
    "      f.write('\\n')\n",
    "f.close() \n",
    "\n",
    "# Randomly reshuffling the created text file\n",
    "with open(PATH_FILES) as infile, open(PATH_FILES1, 'w') as outfile:\n",
    "    lines = infile.readlines()\n",
    "    indices = list(range(len(lines)))\n",
    "    random.shuffle(indices)\n",
    "    for i in indices:\n",
    "      outfile.write(lines[i])\n",
    "infile.close()\n",
    "outfile.close()\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beeed2a-a43d-4a21-9797-09cfb52e93bb",
   "metadata": {},
   "source": [
    "## 5. Use k-fold cross validation to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a533125e-73d7-413c-8d24-bec59e15ad2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Fold 2:\n",
      "Fold 3:\n",
      "Fold 4:\n",
      "Fold 5:\n",
      "Fold 6:\n",
      "Fold 7:\n",
      "Fold 8:\n",
      "Fold 9:\n",
      "Fold 10:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "PATH_FILES1 = \"./data_splits_obfus_aug1\"\n",
    "PATH_FILES = \"./data_splits_obfus_aug1/all_shuffle.txt\"\n",
    "\n",
    "#sample size+1 total size +1 is 9345\n",
    "k=9345\n",
    "\n",
    "X = np.array([i for i in range(1,k)])\n",
    "#y = np.array([1, 2, 3, 4])\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "#kf.get_n_splits(X)\n",
    "#print(kf)\n",
    "with open(PATH_FILES) as infile:\n",
    "    lines = infile.readlines()\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "         print(f\"Fold {i+1}:\")\n",
    "         train_file_path = os.path.join(PATH_FILES1, \"train\"+str(i+1)+\".txt\")\n",
    "         test_file_path = os.path.join(PATH_FILES1, \"test\"+str(i+1)+\".txt\")\n",
    "         valid_file_path = os.path.join(PATH_FILES1, \"valid\"+str(i+1)+\".txt\")\n",
    "         with open(train_file_path, 'w') as trainfile, open(test_file_path, 'w') as testfile, open(valid_file_path, 'w') as validfile:\n",
    "            for j in train_index:\n",
    "              trainfile.write(lines[j])\n",
    "            new_test_index = np.array_split(test_index,2)[0]\n",
    "            for j in new_test_index:\n",
    "              testfile.write(lines[j])\n",
    "            valid_index = np.array_split(test_index,2)[1]\n",
    "            for j in valid_index:\n",
    "              validfile.write(lines[j])\n",
    "         trainfile.close()\n",
    "         testfile.close()\n",
    "         validfile.close()\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fac8-48cc-4dd7-8e2d-2b33e1b6f083",
   "metadata": {},
   "source": [
    "## Creating obfuscated test sets from the non-obfuscated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b20ee2f-714a-423b-8d05-48cb5b3b7d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Length of testfile set   468\n",
      "Length of same is   322\n",
      "Length of obfus file set   428\n",
      "Randomly select 146 obfuscated files for test1 file\n",
      "Writing 468 lines in test1 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 2:\n",
      "Length of testfile set   468\n",
      "Length of same is   332\n",
      "Length of obfus file set   428\n",
      "Randomly select 136 obfuscated files for test2 file\n",
      "Writing 468 lines in test2 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 3:\n",
      "Length of testfile set   468\n",
      "Length of same is   293\n",
      "Length of obfus file set   428\n",
      "Randomly select 175 obfuscated files for test3 file\n",
      "Writing 468 lines in test3 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 4:\n",
      "Length of testfile set   467\n",
      "Length of same is   302\n",
      "Length of obfus file set   428\n",
      "Randomly select 165 obfuscated files for test4 file\n",
      "Writing 467 lines in test4 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 5:\n",
      "Length of testfile set   467\n",
      "Length of same is   323\n",
      "Length of obfus file set   428\n",
      "Randomly select 144 obfuscated files for test5 file\n",
      "Writing 467 lines in test5 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 6:\n",
      "Length of testfile set   467\n",
      "Length of same is   314\n",
      "Length of obfus file set   428\n",
      "Randomly select 153 obfuscated files for test6 file\n",
      "Writing 467 lines in test6 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 7:\n",
      "Length of testfile set   467\n",
      "Length of same is   331\n",
      "Length of obfus file set   428\n",
      "Randomly select 136 obfuscated files for test7 file\n",
      "Writing 467 lines in test7 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 8:\n",
      "Length of testfile set   467\n",
      "Length of same is   311\n",
      "Length of obfus file set   428\n",
      "Randomly select 156 obfuscated files for test8 file\n",
      "Writing 467 lines in test8 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 9:\n",
      "Length of testfile set   467\n",
      "Length of same is   322\n",
      "Length of obfus file set   428\n",
      "Randomly select 145 obfuscated files for test9 file\n",
      "Writing 467 lines in test9 file\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Fold 10:\n",
      "Length of testfile set   467\n",
      "Length of same is   301\n",
      "Length of obfus file set   428\n",
      "Randomly select 166 obfuscated files for test10 file\n",
      "Writing 467 lines in test10 file\n",
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130/116891691.py:51: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  same = same | set(random.sample(obfus_file_set, len(testfile_set)))\n"
     ]
    }
   ],
   "source": [
    "# Input files: train, test, and valid files generated fron the non-obfuscated dataset\n",
    "# Input file: all_obfuscated.txt file containing all obfuscated samples randomly shuffled\n",
    "# Output: train, test, and valid files with test files samples replaced by their corresponding obfusated counterparts if present. \n",
    "#         If not select a file at random from all_obfuscated.txt which is not found in the train, valid or test datasets\n",
    "\n",
    "import os \n",
    "import random\n",
    "\n",
    "#setting up input/output files and/or folders \n",
    "non_obfuscated_path = \"./data_splits_hilbert\"\n",
    "all_obfuscated_files = \"./data_splits_obfuscated1/all_shuffle.txt\"\n",
    "obfus_test_path = \"./data_splits_obfuscated1\"\n",
    "\n",
    "#looping through the 10 test files\n",
    "for i in range(1,11):\n",
    "    print(f\"Fold {i}:\")\n",
    "    #setting input files paths\n",
    "    train_file_path = os.path.join(non_obfuscated_path, \"train\"+str(i)+\".txt\")\n",
    "    test_file_path = os.path.join(non_obfuscated_path, \"test\"+str(i)+\".txt\")\n",
    "    valid_file_path = os.path.join(non_obfuscated_path, \"valid\"+str(i)+\".txt\")\n",
    "    with open(all_obfuscated_files, 'r')  as obfus_file, open(test_file_path, 'r') as testfile, open(train_file_path, 'r') as trainfile, open(valid_file_path, 'r') as validfile:\n",
    "        #get equivalent obfuscated versions of test files\n",
    "        testfile_lines = testfile.readlines()\n",
    "        obfusfile_lines = obfus_file.readlines()\n",
    "        testfile_set = set(testfile_lines)\n",
    "        #obfus_file_set = set(obfusfile_lines)\n",
    "        obfus_file_set = set(f.replace(\"_obfuscated\", \"\")  for f in obfusfile_lines)\n",
    "        print(\"Length of testfile set  \", len( testfile_set))\n",
    "        same = obfus_file_set & testfile_set\n",
    "        print(\"Length of same is  \", len(same))\n",
    "        #remove files in testset that are already n the obfuscated dataset\n",
    "        testfile_set.difference_update(obfus_file_set)\n",
    "        if len(testfile_set) == 0:\n",
    "            print(f\"Great!!! All files in test{i} have obfuscated versions\")\n",
    "        else:\n",
    "            trainfile_lines = trainfile.readlines()\n",
    "            validfile_lines = validfile.readlines()\n",
    "            trainfile_set = set(trainfile_lines)\n",
    "            validfile_set = set(validfile_lines)\n",
    "            #Create universal set of files that can n longer be included in the testset\n",
    "            all_set = same | trainfile_set | validfile_set\n",
    "            obfus_file_set.difference_update(all_set)\n",
    "            print(\"Length of obfus file set  \", len( obfus_file_set ))\n",
    "            if len(obfus_file_set)==0:\n",
    "                print(f\"All obfuscated files are already in trainset, validset and test{i}\")\n",
    "            elif len(obfus_file_set)<=len(testfile_set):\n",
    "                print(f\"All obfuscated less than or equal to required obfuscated test{i}\")\n",
    "                same = same | obfus_file_set\n",
    "            else:\n",
    "                print(f\"Randomly select {len(testfile_set)} obfuscated files for test{i} file\")\n",
    "                same = same | set(random.sample(obfus_file_set, len(testfile_set)))\n",
    "        #Create new obfuscated test file\n",
    "        new_test_file_path = os.path.join(obfus_test_path, \"test\"+str(i)+\".txt\")\n",
    "        with open(new_test_file_path, 'w') as new_test_file:\n",
    "            if len(same) == 0:\n",
    "                print(f\"Fatal error:Obfuscated testset is empty for test{i} file\")\n",
    "                for line in testfile_lines:\n",
    "                     new_test_file.write(line.replace(\".png\",\"_obfuscated.png\"))\n",
    "            else:\n",
    "                print(f\"Writing {len(same)} lines in test{i} file\")\n",
    "                for line in same:\n",
    "                     new_test_file.write(line.replace(\".png\",\"_obfuscated.png\"))\n",
    "        new_test_file.close()\n",
    "    obfus_file.close()\n",
    "    trainfile.close()\n",
    "    testfile.close()\n",
    "    validfile.close()\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea944e63-aeee-46d2-a191-6b48d2e23844",
   "metadata": {},
   "source": [
    "## copy files from one directory to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12203d2e-df59-48f7-8faa-c6bb16b9924f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files move count =  2073\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "dest_dir = './exp1/images/malware'\n",
    "#malware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/malware\"\n",
    "source_dir = \"./obfuscated_img/malware\"\n",
    "#goodware_dest_dir = \"/media/ngaibe/EXTERNAL_USB/MyDatasets/Experiment_dataset/goodware\"\n",
    "\n",
    "\n",
    "count=0\n",
    "for path in os.listdir(source_dir):\n",
    "    # check if current path is a file\n",
    "    file = os.path.join(source_dir, path)\n",
    "    file1 = os.path.join(dest_dir, path)\n",
    "    if os.path.isfile(file):\n",
    "        shutil.copy(file,file1)\n",
    "        count += 1\n",
    "print('files move count = ',count)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
